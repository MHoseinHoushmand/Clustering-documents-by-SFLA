{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHoseinHoushmand/Clustering_by_SLFA/blob/main/Clustering_by_SLFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ovHcWlfr8Ao9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from numpy.linalg import norm\n",
        "import operator\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2J1TujL22H1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830a0fc3-5274-47e7-9cb3-85cdc740b957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3758 documents - 4 categories\n",
            "[3 2 0 0 1 1 2 3 2 1 3 1 3 0 0 2 1 0 3 1 0 2 1 0 2 2 1 1 3 3 0 1 1 2 3 3 2\n",
            " 1 1 1 2 1 2 3 2 0 0 2 2 1 3 0 1 2 2 3 1 0 1 2 0 1 3 1 3 2 0 3 1 1 0 3 3 0\n",
            " 1 0 2 0 2 1 2 2 0 2 3 2 1 2 0 2 0 1 1 3 3 2 0 2 0 3 1 0 0 1 2 3 3 0 3 3 2\n",
            " 1 0 0 1 3 2 2 1 2 2 0 2 3 2 1 0 1 2 3 2 2 2 3 3 0 3 3 0 0 2 0 1 3 1 2 1 1\n",
            " 3 2 3 3 0 1 3 3 2 2 2 3 2 0 2 0 1 3 3 1 0 2 2 2 2 3 2 3 1 1 1 1 2 3 3 1 2\n",
            " 1 1 2 3 1 0 2 2 2 0 2 3 3 2 1 1 0 3 2 0 3 2 3 0 2 3 3 0 1 3 1 0 3 0 0 2 3\n",
            " 3 3 1 1 1 3 1 0 3 1 0 3 2 3 3 0 0 1 1 3 2 2 2 1 3 0 2 3 3 0 1 3 2 0 3 2 0\n",
            " 0 0 1 2 3 3 3 3 2 1 3 2 2 2 1 0 3 2 2 3 0 3 2 1 0 2 1 2 2 2 0 2 2 2 1 2 3\n",
            " 0 0 3 2 3 0 3 3 0 0 0 0 0 0 2 0 2 3 3 3 3 0 3 0 3 2 1 3 1 2 2 0 3 0 1 1 1\n",
            " 1 2 2 3 1 1 2 0 0 3 1 0 1 1 2 1 3 3 3 3 2 2 3 1 3 1 0 0 0 2 3 2 2 1 0 1 1\n",
            " 2 0 3 3 3 3 1 0 0 0 3 2 2 1 2 2 0 1 3 3 3 1 2 0 2 1 1 1 2 3 3 3 0 1 1 0 3\n",
            " 2 1 3 3 0 3 2 2 3 3 2 2 1 1 2 2 3 2 0 3 0 3 2 3 1 3 3 1 1 0 2 1 1 3 0 2 0\n",
            " 3 3 3 2 1 2 3 1 2 3 3 1 1 1 3 3 1 3 2 2 0 1 2 2 1 0 0 3 1 1 1 1 1 3 1 3 1\n",
            " 2 3 3 2 0 1 2 3 3 0 3 0 3 0 3 2 0 3 2]\n"
          ]
        }
      ],
      "source": [
        "categories = [  #Select 4 categories from fetch_20newsgroups dataset\n",
        "    \"alt.atheism\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "    \"rec.sport.hockey\",\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups( #Preprocessing before using dataset\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "labels = dataset.target[0:500]\n",
        "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
        "true_k = unique_labels.shape[0]\n",
        "print(f\"{len(dataset.data)} documents - {true_k} categories\")\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERPNfqNYATbl"
      },
      "outputs": [],
      "source": [
        "# Vectorize all document as their term frequency(tfidf score)\n",
        "def docs_as_tfidf(docs):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "     max_df=0.5, #Removing terms that are used in more than 50% of articles\n",
        "     min_df=5,   #Removing terms that are not used in less than 10 of articles\n",
        "     stop_words=\"english\",\n",
        "     #  max_features=1000,\n",
        "  )\n",
        "  docs_vector = vectorizer.fit_transform(docs)\n",
        "  return docs_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y_4pWLVAZIh"
      },
      "outputs": [],
      "source": [
        "def cosin_sim(a,b):\n",
        "   return cosine_similarity([a], [b])[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cluster:\n",
        "     def __init__(self):\n",
        "         documents = []\n",
        "         size = len(self.documents)\n",
        "         doc_mean = []\n",
        "\n",
        "     def get_doc_mean(self):\n",
        "        self.doc_mean = np.average(self.documents, axis=0)\n",
        "        return self.doc_mean\n",
        "\n",
        "     def SSE(self):     #Sum of squared error(SSE) as similarity of each documents with the cluster mean in document\n",
        "         doc_mean = self.doc_mean\n",
        "         sse=0\n",
        "         for doc in self.documents:\n",
        "             sse += cosin_sim(doc,doc_mean)**2\n",
        "             sse = sse/self.size\n",
        "         return sse\n"
      ],
      "metadata": {
        "id": "iBMKJt5lzl3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Frog:\n",
        "     def __init__(self,answer,docs_vector,n_clusters):\n",
        "        answer = answer\n",
        "        value = self.fitness(docs_vector,n_clusters)\n",
        "        tuplefrom = (answer,self.value)\n",
        "\n",
        "\n",
        "     def build_clusters(self,docs_vector,n_clusters):\n",
        "          clusters = []\n",
        "          for i in range(n_clusters):\n",
        "             cluster = Cluster()\n",
        "             clusters.append(cluster)\n",
        "          for j in range(len(self.answer)):\n",
        "             if -1 < self.answer[j]:\n",
        "                clusters[self.answer[j]].documents.append(docs_vector[j])\n",
        "          return clusters\n",
        "\n",
        "\n",
        "     def WC(self,clusters):   #Calculate similarity within clusters\n",
        "        WC = 0\n",
        "        for cluster in clusters:\n",
        "            WC += cluster.SSE()\n",
        "        return WC\n",
        "\n",
        "\n",
        "     def BC(self,doc_means):#Calculate similarity between clusters\n",
        "          BC=0\n",
        "          size = len(doc_means)\n",
        "          for i in range(size):\n",
        "              for j in range(i+1,size):\n",
        "                  BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "          return BC\n",
        "\n",
        "\n",
        "     def fitness(self,docs_vector,n_clusters):\n",
        "           doc_means = []\n",
        "           clusters = self.build_clusters(docs_vector,n_clusters)\n",
        "           for i in range(n_clusters):\n",
        "               doc_means.append(\n",
        "                  np.average(clusters[i], axis=0)\n",
        "               )\n",
        "           wc = self.WC(clusters) #Calculate similarity within clusters\n",
        "           bc = self.BC(doc_means) #Calculate similarity between clusters\n",
        "           fitness = wc/bc\n",
        "           return fitness\n",
        "\n",
        "\n",
        "     def cross_over(self,frog_b): #perform 2 points cross over\n",
        "           frog_size = len(self.answer)\n",
        "           points = sorted(np.random.choice(np.arange(0,frog_size), size=2, replace=False))\n",
        "           answer1 = self.answer[:points[0]] + frog_b.answer[points[0]:points[1]] + self.answer[points[1]:]\n",
        "           answer2 = frog_b.answer[:points[0]] + self.answer[points[0]:points[1]] + frog_b.answer[points[1]:]\n",
        "           child1 = Frog(answer1)\n",
        "           child2 = Frog(answer2)\n",
        "           if child1.value > child2.value: # return best child\n",
        "               return (child1 , child1.value)\n",
        "           else :\n",
        "               return (child2 , child2.value)\n",
        "\n",
        "     def mutation(self,clusters_size):\n",
        "         new_ans = list(self.answer)\n",
        "         size = int(len(self.answer)/4)\n",
        "         indexes = np.random.choice(np.arange(0,len(self.answer)), size=size, replace=False)\n",
        "         values= [random.randint(0, 3) for _ in range(size)]\n",
        "         for i in range(size):\n",
        "            new_ans[indexes[i]] = values[i]\n",
        "         child = Frog(tuple(new_ans))\n",
        "         return  child\n"
      ],
      "metadata": {
        "id": "cVyGX4nWmhKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Memplex:\n",
        "     def __init__(self):\n",
        "         frogs = []\n",
        "\n",
        "     def best(self):\n",
        "        if len(self.frogs) > 0\n",
        "           return self.frogs[0]\n",
        "\n",
        "     def worst(self,frogs):\n",
        "        if len(self.frogs) > 0\n",
        "           return self.frogs[len(self.frogs)-1]\n",
        "\n",
        "     def frogs_to_remove(self,sub_memplex):\n",
        "         for item in sub_memplex:\n",
        "            self.frogs.remove(item)\n",
        "         return self\n",
        "\n",
        "     def add_frogs(self,submemplex):\n",
        "         self.frogs = self.frogs + submemplex.frogs\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CL-MOSXd5xjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Submemplex:\n",
        "     def __init__(self, memplex ,n_submemplex ):\n",
        "         frogs = []\n",
        "         prob_list = []\n",
        "         keys = []\n",
        "         for i in range(memplex_size):\n",
        "             for j in range(2*(memplex_size-i)):\n",
        "                 prob_list.append(i)\n",
        "         k=0\n",
        "         while(k!=n_submemplex):\n",
        "            index = random.choice(prob_list)\n",
        "            key = memplex.frogs[index][0]\n",
        "            if key not in keys:\n",
        "                frogs.append(memplex.frogs[index])\n",
        "                keys.append(key)\n",
        "                k+=1\n",
        "\n",
        "     def best(self):\n",
        "        if len(self.frogs) > 0\n",
        "           return self.frogs[0]\n",
        "\n",
        "     def worst(self,frogs):\n",
        "        if len(self.frogs) > 0\n",
        "           return self.frogs[len(self.frogs)-1]\n",
        "\n",
        "     def add_frog(self,frog):\n",
        "        index = 0\n",
        "        for tfrog in self.frogs:\n",
        "            if frog.value >  tfrog.value:\n",
        "                self.frogs.insert(index,frog)\n",
        "            index += 1"
      ],
      "metadata": {
        "id": "TjSRqkS6gsQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Population:\n",
        "     def __init__(self,n_clusters, n_population ,n_docs, docs_vector):\n",
        "        answers = np.random.randint(0, n_clusters, size=(n_population , n_docs))\n",
        "        frogs = []\n",
        "        for answer in range(answers):\n",
        "           frog = Frog(answer,docs_vector,n_clusters)\n",
        "           frogs.append(frog)\n",
        "\n",
        "     def clear_frogs(self):\n",
        "        self.frogs.clear()\n",
        "\n",
        "     # Best frog in population\n",
        "     def global_best(self,memplexes):\n",
        "        local_bests = []\n",
        "        for memplex in memplexes:\n",
        "            local_best =  max(memplex, key=lambda frog: frog.value)\n",
        "            local_bests.append(local_best)\n",
        "        global_best =  max(local_bests, key=lambda frog: frog.value)\n",
        "        return global_best\n",
        "\n",
        "     def shufeling(self,memplexes):\n",
        "         output = []\n",
        "         for memplex in memplexes:\n",
        "            output = output+ memplex\n",
        "         self.frogs = output\n"
      ],
      "metadata": {
        "id": "fMar5YE7ryrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SLFA:\n",
        "     def  __init__(self,n_clusters, max_iteration, docs):\n",
        "        n_clusters = n_clusters\n",
        "        max_iteration =  max_iteration\n",
        "        docs = docs\n",
        "        n_population = 400 # Frogs number\n",
        "        memplex_size = 20 #define as m\n",
        "        n_memplex = 20 #define as n\n",
        "        local_iteration = 10 #Iteration As local search\n",
        "        n_submemplex = 5\n",
        "        docs_vector = docs_as_tfidf(docs)  #Convert documents as tfidf values\n",
        "\n",
        "\n",
        "     def create_memplexes(self,population,n_memplex):\n",
        "             population = sorted(population, key=lambda frog: frog.value)\n",
        "             memplexes = []\n",
        "             for i in range(memplex_num):\n",
        "                 memplex = Memplex()\n",
        "                 memplexes.append(memplex)\n",
        "             for i in range(self.n_population):\n",
        "                 memplexes[i % memplex_num].frogs.append(population[i])\n",
        "             return memplexes\n",
        "\n",
        "\n",
        "\n",
        "     def search(self):\n",
        "        population = Population(self.n_clusters, self.n_population, self.n_docs, self.docs_vector)\n",
        "        memplexes = self.Create_memplexes(population,self.n_memplex)\n",
        "        for i in range(max_iteration):\n",
        "           memplexes = self.create_memplexes(population,self.n_memplex)\n",
        "           population.clear_frogs()\n",
        "           for j in range(self.n_memplex):\n",
        "               submemplex = Submemplex(memplexes[j],self.n_submemplex)\n",
        "               memplexes[j].frogs_to_remove(submemplex)\n",
        "               for k in range(local_iteration):\n",
        "                    lfrog_best = submemplex.best()\n",
        "                    lfrog_worst = submemplex.worst()\n",
        "                    frog_out = lfrog_worst.cross_over(lfrog_best)\n",
        "                    if (lfrog_worst.value < frog_out.value ):\n",
        "                         submemplex.frogs.remove(lfrog_worst)\n",
        "                         submemplex.add_frog(frog_out)\n",
        "                    else:\n",
        "                         gfrog_best = population.global_best(memplexes)\n",
        "                         frog_out = cross_over(gfrog_best[0],lfrog_worst[0])\n",
        "                         if (lfrog_worst[1]<frog_out[1]):\n",
        "                              submemplex.remove(lfrog_worst)\n",
        "                              submemplex.add_frog(frog_out)\n",
        "                         else:\n",
        "                              frog_out = gfrog_best.mutation(n_clusters)\n",
        "                              submemplex.remove(lfrog_worst)\n",
        "                              submemplex.append(frog_out)\n",
        "               memplexes[j].add_frogs(submemplex)\n",
        "           gfrog_best = population.global_best(memplexes)\n",
        "           population.shufeling(memplexes)\n",
        ""
      ],
      "metadata": {
        "id": "Hvh9lxf7ddZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = dataset.data[0:500]\n",
        "slfa = SLFA(4,50,docs)\n"
      ],
      "metadata": {
        "id": "ull9d7AGWeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT5WJIYfAWKq",
        "outputId": "d9526c4e-ce80-4f14-ccc7-1a4fd2d82b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19326683304032288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18415250785552104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2007137789503999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38653366608064577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16495515310449496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1601442908505651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.19326683304032288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16850914326011535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14618549985564544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14727476761437713, 0.0, 0.0, 0.22157851297615083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15722554087429888, 0.0, 0.0, 0.2007137789503999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22157851297615083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13580127590355345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20501724188127193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14618549985564544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13108313813948552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "population_size = 400 # Frogs number\n",
        "memplex_num = 20 #define as m\n",
        "memplex_size = 20 #define as n\n",
        "max_iteration = 100 #Total Iteration\n",
        "local_iteration = 10 #Iteration As local search\n",
        "n_clusters = 4\n",
        "docs = dataset.data[0:500]\n",
        "docs_vector = docs_as_tfidf(docs)\n",
        "print(list(docs_vector[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU_Vs63UAfxR"
      },
      "outputs": [],
      "source": [
        "#Calculate sum of squared error(SSE) as similarity of each documents with the cluster mean in document\n",
        "def SSE(cluster,doc_mean):\n",
        "  size = len(cluster)\n",
        "  sse=0\n",
        "  for doc in cluster:\n",
        "    sse += cosin_sim(doc,doc_mean)**2\n",
        "  sse = sse/size\n",
        "  return sse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djW8MEZJAhbt"
      },
      "outputs": [],
      "source": [
        "#Calculate similarity between clusters\n",
        "def BC(doc_means):\n",
        "   BC=0\n",
        "   size = len(doc_means)\n",
        "   for i in range(size):\n",
        "      for j in range(i+1,size):\n",
        "          BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "   return BC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8QcCXYyAlbp"
      },
      "outputs": [],
      "source": [
        "#Calculate similarity within clusters\n",
        "def WC(clusters):\n",
        "    WC = 0\n",
        "    for cluster in clusters:\n",
        "        doc_mean = np.average(cluster, axis=0)\n",
        "        WC += SSE(cluster,doc_mean)\n",
        "    return WC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctgFGZq4AoMy"
      },
      "outputs": [],
      "source": [
        "def build_clusters(answer,docs_vector,n_clusters):\n",
        "   clusters = []\n",
        "   for i in range(n_clusters):\n",
        "       clusters.append([])\n",
        "   for j in range(len(answer)):\n",
        "       if -1 < answer[j]:\n",
        "        clusters[answer[j]].append(docs_vector[j])\n",
        "   return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxmKqWWwAr-p"
      },
      "outputs": [],
      "source": [
        "def fitness(answer,docs_vector,size):\n",
        "   doc_means = []\n",
        "   clusters = build_clusters(answer,docs_vector,size)\n",
        "   for i in range(size):\n",
        "       doc_means.append(\n",
        "          np.average(clusters[i], axis=0)\n",
        "       )\n",
        "   wc = WC(clusters) #Calculate similarity within clusters\n",
        "   bc = BC(doc_means) #Calculate similarity between clusters\n",
        "   fitness = wc/bc\n",
        "   return fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9KMmJLRAyA9"
      },
      "outputs": [],
      "source": [
        "#perform 2 points cross over\n",
        "def cross_over(answer_a,answer_b):\n",
        "    frog_size = len(answer_a)\n",
        "    points = sorted(np.random.choice(np.arange(0,frog_size), size=2, replace=False))\n",
        "    child1 = answer_a[:points[0]] + answer_b[points[0]:points[1]] + answer_a[points[1]:]\n",
        "    child2 = answer_b[:points[0]] + answer_a[points[0]:points[1]] + answer_b[points[1]:]\n",
        "    fitness1 =  fitness(child1 ,docs_vector,n_clusters)\n",
        "    fitness2 = fitness(child2 ,docs_vector,n_clusters)\n",
        "    if fitness1 > fitness2: # return best child\n",
        "       return (child1 , fitness1)\n",
        "    else :\n",
        "       return (child2 , fitness2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7IQ2BZ6A2mE"
      },
      "outputs": [],
      "source": [
        "def best_and_worst(answers):\n",
        "     best =  max(answers, key=lambda x:x[1])\n",
        "     worst = min(answers, key=lambda x:x[1])\n",
        "     return best , worst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl1HNpfnA4aH"
      },
      "outputs": [],
      "source": [
        "# Best frog in population\n",
        "def global_best(memplexes):\n",
        "     local_bests = []\n",
        "     for memplex in memplexes:\n",
        "         local_best =   max(memplex, key=lambda x:x[1])\n",
        "         local_bests.append(local_best)\n",
        "     global_best = max(local_bests, key=lambda x:x[1])\n",
        "     return global_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyxvE3VTA8CF"
      },
      "outputs": [],
      "source": [
        "def frogs_to_remove(sub_memplex , memplex):\n",
        "    for item in sub_memplex:\n",
        "       memplex.remove(item)\n",
        "    return memplex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_So4_XjBCHg"
      },
      "outputs": [],
      "source": [
        "def mutation(global_best,clusters_size):\n",
        "    new_ans = list(global_best)\n",
        "    size = int(len(global_best)/4)\n",
        "    indexes = np.random.choice(np.arange(0,len(global_best)), size=size, replace=False)\n",
        "    values= [random.randint(0, 3) for _ in range(size)]\n",
        "    for i in range(size):\n",
        "      new_ans[indexes[i]] = values[i]\n",
        "    return tuple(new_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNAgxJGYBEX9"
      },
      "outputs": [],
      "source": [
        "def Create_memplexes(population,memplex_num):\n",
        "     population = list(reversed(sorted(population, key=lambda x: x[1])))\n",
        "     memplexes = []\n",
        "     population_size = len(population)\n",
        "     for i in range(memplex_num):\n",
        "         memplexes.append([])\n",
        "     for i in range(population_size):\n",
        "         memplexes[i % memplex_num].append(population[i])\n",
        "     return memplexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC9UfM-YnV8S"
      },
      "outputs": [],
      "source": [
        "def create_submemplex(memplex,memplex_size, submemplex_size):\n",
        "    sub_memplex = []\n",
        "    prob_list = []\n",
        "    keys = []\n",
        "    for i in range(memplex_size):\n",
        "       for j in range(2*(memplex_size-i)):\n",
        "          prob_list.append(i)\n",
        "    k=0\n",
        "    while(k!=submemplex_size):\n",
        "       index = random.choice(prob_list)\n",
        "       key = memplex[index][0]\n",
        "       if key not in keys:\n",
        "           sub_memplex.append(memplex[index])\n",
        "           keys.append(key)\n",
        "           k+=1\n",
        "    return sub_memplex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WghpigCiBH25"
      },
      "outputs": [],
      "source": [
        "#sh\n",
        "def shufeling(memplexes):\n",
        "    output = []\n",
        "    for memplex in memplexes:\n",
        "        output = output+ memplex\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEofbesdBRJZ"
      },
      "outputs": [],
      "source": [
        "def frog_leaping_search(docs_vector):\n",
        "                     answers=np.random.randint(0, n_clusters, size=(population_size , len(docs)))\n",
        "                     population = []\n",
        "                     i=0\n",
        "                     for answer in answers:\n",
        "                        i+=1\n",
        "                        frog = (tuple(answer),fitness(answer,docs_vector,n_clusters))\n",
        "                        population.append(frog)\n",
        "                        print(i,frog[1])\n",
        "                     for i in range(max_iteration):\n",
        "                        memplexes = Create_memplexes(population, memplex_num)\n",
        "                        population.clear()\n",
        "                        for j in range(memplex_num):\n",
        "                            print(i,j,len(memplexes[j]))\n",
        "                            sub_memplex = create_submemplex(memplexes[j],memplex_size, 5)\n",
        "                            memplexes[j] =  frogs_to_remove(sub_memplex,memplexes[j])\n",
        "                            for k in range(local_iteration):\n",
        "                                ans_best, ans_worst = best_and_worst(sub_memplex)\n",
        "                                ans_out = cross_over(ans_best[0],ans_worst[0])\n",
        "                                if (ans_worst[1]<ans_out[1]):\n",
        "                                    sub_memplex.remove(ans_worst)\n",
        "                                    sub_memplex.append(ans_out)\n",
        "                                else:\n",
        "                                    g_best = global_best(memplexes)\n",
        "                                    ans_out = cross_over(g_best[0],ans_worst[0])\n",
        "                                    if (ans_worst[1]<ans_out[1]):\n",
        "                                       sub_memplex.remove(ans_worst)\n",
        "                                       sub_memplex.append(ans_out)\n",
        "                                    else:\n",
        "                                        ans_out = mutation(g_best[0],n_clusters)\n",
        "                                        fitness_out = fitness(ans_out,docs_vector,n_clusters)\n",
        "                                        sub_memplex.remove(ans_worst)\n",
        "                                        sub_memplex.append((ans_out , fitness_out))\n",
        "                            memplexes[j]= memplexes[j]+sub_memplex\n",
        "                            print(i,j,len(memplexes[j]))\n",
        "                        g_best = global_best(memplexes)\n",
        "                        print(g_best[0])\n",
        "                        print(g_best[1])\n",
        "                        population = shufeling(memplexes)\n",
        "                        print(len(population))\n",
        "                     return g_best, g_value, population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykAWu-IWkba0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0FrmD4etKFsn",
        "outputId": "adb07b8c-d969-4782-c2e3-93dc38b7d243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.04153801244198741\n",
            "2 0.038705126975120796\n",
            "3 0.0393280032847259\n",
            "4 0.04044760737533567\n",
            "5 0.04162716949285829\n",
            "6 0.04137034125582893\n",
            "7 0.03966440660320541\n",
            "8 0.04086095183883073\n",
            "9 0.040232877486579235\n",
            "10 0.03840422792476109\n",
            "11 0.04026613942081062\n",
            "12 0.040893627223279175\n",
            "13 0.03896096054731363\n",
            "14 0.04076740024544587\n",
            "15 0.038350056943709035\n",
            "16 0.039100375557676106\n",
            "17 0.03985727809625182\n",
            "18 0.040169041860323565\n",
            "19 0.0398524139980088\n",
            "20 0.03974948305853104\n",
            "21 0.03987611727915797\n",
            "22 0.042356223745631125\n",
            "23 0.03983827695558289\n",
            "24 0.039956119723999775\n",
            "25 0.040706079460927094\n",
            "26 0.03940071778029402\n",
            "27 0.038399590714279876\n",
            "28 0.04057936487489854\n",
            "29 0.03947215394108695\n",
            "30 0.041718535459844386\n",
            "31 0.039916965357627746\n",
            "32 0.0398572423132548\n",
            "33 0.040183818216792615\n",
            "34 0.039657688998500695\n",
            "35 0.039176128952048445\n",
            "36 0.04032133192073559\n",
            "37 0.04012883160435416\n",
            "38 0.0396563606734277\n",
            "39 0.04105232920630757\n",
            "40 0.039609391605790634\n",
            "41 0.039567670909102765\n",
            "42 0.04040460611524923\n",
            "43 0.03974270873774837\n",
            "44 0.04086075248197557\n",
            "45 0.03976108474445279\n",
            "46 0.040089975764655776\n",
            "47 0.040446663778266306\n",
            "48 0.03841094637808221\n",
            "49 0.03932261316385831\n",
            "50 0.041097480938485816\n",
            "51 0.04089676820137497\n",
            "52 0.04052696063242041\n",
            "53 0.03989332946179053\n",
            "54 0.03884789331433331\n",
            "55 0.039968435762798966\n",
            "56 0.041555765854714245\n",
            "57 0.04011103417942206\n",
            "58 0.03967822154676472\n",
            "59 0.04008627347791455\n",
            "60 0.040428121403412724\n",
            "61 0.039337109354328055\n",
            "62 0.03990160170330574\n",
            "63 0.04017484373167144\n",
            "64 0.04000894794677536\n",
            "65 0.039463109160436424\n",
            "66 0.040309467371191975\n",
            "67 0.040796845908276855\n",
            "68 0.039659647331952395\n",
            "69 0.04046414689041911\n",
            "70 0.03986068037552522\n",
            "71 0.039851607068992816\n",
            "72 0.03972991044892111\n",
            "73 0.03926764316793451\n",
            "74 0.041650855291896056\n",
            "75 0.04195204069196112\n",
            "76 0.03989611195974589\n",
            "77 0.04185004644830393\n",
            "78 0.039382747939239474\n",
            "79 0.039418442607128706\n",
            "80 0.040594954390148305\n",
            "81 0.03899721352806599\n",
            "82 0.03879743405010242\n",
            "83 0.03956890104645445\n",
            "84 0.04054231519748081\n",
            "85 0.039651478230359985\n",
            "86 0.04043359412343828\n",
            "87 0.03958694380351251\n",
            "88 0.040518785804027985\n",
            "89 0.03923745482436202\n",
            "90 0.04099479135910035\n",
            "91 0.04175598356991659\n",
            "92 0.03832907507100606\n",
            "93 0.03912868210647409\n",
            "94 0.039652349557258666\n",
            "95 0.039271641780146936\n",
            "96 0.0416784047178317\n",
            "97 0.04053017447658536\n",
            "98 0.040364209124127165\n",
            "99 0.04061086559323825\n",
            "100 0.039730622349801535\n",
            "101 0.03951618951242926\n",
            "102 0.04014813387569741\n",
            "103 0.03944355239900123\n",
            "104 0.04282685636509802\n",
            "105 0.04049847902453192\n",
            "106 0.03977391635168149\n",
            "107 0.03923190020069887\n",
            "108 0.03969297120483234\n",
            "109 0.040963606496834996\n",
            "110 0.04127360581527262\n",
            "111 0.03986850712824073\n",
            "112 0.04089800375148625\n",
            "113 0.04028639217340284\n",
            "114 0.03893523457979294\n",
            "115 0.038737979978087166\n",
            "116 0.03879433038701927\n",
            "117 0.03908746013008485\n",
            "118 0.04210091228665278\n",
            "119 0.040359088187795586\n",
            "120 0.03994393912440465\n",
            "121 0.03984350495978679\n",
            "122 0.042221500944422\n",
            "123 0.041372106457507295\n",
            "124 0.03888617669879582\n",
            "125 0.041703807629012324\n",
            "126 0.039230535798854445\n",
            "127 0.042319482799942035\n",
            "128 0.040286411059235035\n",
            "129 0.04161110804409891\n",
            "130 0.040224218428277\n",
            "131 0.039570266345315304\n",
            "132 0.041806178779735206\n",
            "133 0.03980844774155677\n",
            "134 0.04144470520065229\n",
            "135 0.040253587932548365\n",
            "136 0.04131705895351679\n",
            "137 0.03966992999728179\n",
            "138 0.03898195990393077\n",
            "139 0.04048952483552529\n",
            "140 0.04208380648946353\n",
            "141 0.040748639736796766\n",
            "142 0.040328413428426524\n",
            "143 0.04209421731683311\n",
            "144 0.041386671028902595\n",
            "145 0.03937580733904647\n",
            "146 0.04078236657264892\n",
            "147 0.03970548905690876\n",
            "148 0.03987707628174378\n",
            "149 0.039596951550786325\n",
            "150 0.03972156613948474\n",
            "151 0.04047620093300145\n",
            "152 0.03954806595729823\n",
            "153 0.04284906261244395\n",
            "154 0.04030589580728278\n",
            "155 0.03870066676246931\n",
            "156 0.040890941782011164\n",
            "157 0.03995950805485515\n",
            "158 0.038832659470985416\n",
            "159 0.04067501201138523\n",
            "160 0.03978479744002501\n",
            "161 0.041523685087106514\n",
            "162 0.04017706704038929\n",
            "163 0.039664098500468675\n",
            "164 0.039692057627034684\n",
            "165 0.03861014530718473\n",
            "166 0.03780342760615003\n",
            "167 0.04037652120667844\n",
            "168 0.039803902408445994\n",
            "169 0.04052469866897621\n",
            "170 0.040049806162697675\n",
            "171 0.041021031336575975\n",
            "172 0.0406425785301052\n",
            "173 0.04236793646156119\n",
            "174 0.040450554512119805\n",
            "175 0.04027778246180372\n",
            "176 0.04141649047293258\n",
            "177 0.03949401042425418\n",
            "178 0.04110164631674116\n",
            "179 0.041264104702378075\n",
            "180 0.03910277465585298\n",
            "181 0.0400914307851695\n",
            "182 0.04123736285810848\n",
            "183 0.03946745797788796\n",
            "184 0.039097652227148755\n",
            "185 0.04057966752092128\n",
            "186 0.04164614333692522\n",
            "187 0.04063913646827733\n",
            "188 0.038671376278727285\n",
            "189 0.040874025204601004\n",
            "190 0.04065164876937742\n",
            "191 0.03813064375529155\n",
            "192 0.03846777025702195\n",
            "193 0.03883967644236685\n",
            "194 0.040535096107873356\n",
            "195 0.03949040930981507\n",
            "196 0.040660398412999316\n",
            "197 0.039146726116486896\n",
            "198 0.0418349137825696\n",
            "199 0.04169318527218646\n",
            "200 0.041290855281429985\n",
            "201 0.04024267619681186\n",
            "202 0.0409428427022811\n",
            "203 0.03952450451677436\n",
            "204 0.039751726199521546\n",
            "205 0.03941441322078229\n",
            "206 0.04106635373367931\n",
            "207 0.03978245013075253\n",
            "208 0.0390680345572314\n",
            "209 0.04107385413735204\n",
            "210 0.04082461057495648\n",
            "211 0.04006710578667368\n",
            "212 0.039029508053575336\n",
            "213 0.039468045296071945\n",
            "214 0.04121361621034945\n",
            "215 0.03981390784616603\n",
            "216 0.04008526026455798\n",
            "217 0.03951300347068615\n",
            "218 0.038395112860725444\n",
            "219 0.04161414447529581\n",
            "220 0.04169329259890953\n",
            "221 0.03965411226113299\n",
            "222 0.04012305506717556\n",
            "223 0.03981197124227492\n",
            "224 0.042453999157889735\n",
            "225 0.040417964082245385\n",
            "226 0.040027176259290524\n",
            "227 0.042151359863736554\n",
            "228 0.03884544371864954\n",
            "229 0.0394009248360302\n",
            "230 0.03954424447052837\n",
            "231 0.041206859996561\n",
            "232 0.04134785959641349\n",
            "233 0.041345313559081005\n",
            "234 0.03901286297036023\n",
            "235 0.04044841442199925\n",
            "236 0.04113473341920595\n",
            "237 0.0403601338063248\n",
            "238 0.04069540768913988\n",
            "239 0.03874372342627759\n",
            "240 0.041345576154952324\n",
            "241 0.04005372984924422\n",
            "242 0.04034409924334303\n",
            "243 0.03969318357109833\n",
            "244 0.04010649964252074\n",
            "245 0.03995249919578302\n",
            "246 0.04022463874378727\n",
            "247 0.0384854144910507\n",
            "248 0.039202870111794935\n",
            "249 0.04050528754205284\n",
            "250 0.03799547326501523\n",
            "251 0.03962072079314106\n",
            "252 0.03999718239357249\n",
            "253 0.03833292811274866\n",
            "254 0.04023771115663925\n",
            "255 0.04020440848698051\n",
            "256 0.04043888163608159\n",
            "257 0.04162649471365775\n",
            "258 0.039510074449648845\n",
            "259 0.04078542778304825\n",
            "260 0.040065077979186715\n",
            "261 0.03953128055756607\n",
            "262 0.04058792288874493\n",
            "263 0.03897095390367432\n",
            "264 0.04091932957346292\n",
            "265 0.04141411691584221\n",
            "266 0.04003464528845189\n",
            "267 0.039180204224369755\n",
            "268 0.03897914634131602\n",
            "269 0.04127532609704389\n",
            "270 0.04046158322287089\n",
            "271 0.03851111037045698\n",
            "272 0.0385324122870301\n",
            "273 0.039343546526496034\n",
            "274 0.04084810617386824\n",
            "275 0.04001621616404549\n",
            "276 0.04022334286225441\n",
            "277 0.03897397117509014\n",
            "278 0.03901977299683582\n",
            "279 0.039102192803084565\n",
            "280 0.041896836757825566\n",
            "281 0.03948716966773154\n",
            "282 0.03967286297589193\n",
            "283 0.04080005437071327\n",
            "284 0.04008395361003522\n",
            "285 0.03917962787644078\n",
            "286 0.04093430808712652\n",
            "287 0.039281248066014775\n",
            "288 0.038622705442829974\n",
            "289 0.040177539459017954\n",
            "290 0.03996527286096269\n",
            "291 0.041239845698919225\n",
            "292 0.04010751825416137\n",
            "293 0.037970901522366665\n",
            "294 0.04023986137054685\n",
            "295 0.03883582397188931\n",
            "296 0.04068536405277764\n",
            "297 0.040181637066219474\n",
            "298 0.039560249765033834\n",
            "299 0.041313766964634714\n",
            "300 0.039557164616112674\n",
            "301 0.03993442972250612\n",
            "302 0.039016932090128846\n",
            "303 0.04092825504121711\n",
            "304 0.04137280048025797\n",
            "305 0.0415215582425727\n",
            "306 0.03969015517905474\n",
            "307 0.0406897350900138\n",
            "308 0.03877040455941644\n",
            "309 0.039310706398602305\n",
            "310 0.04028913556726272\n",
            "311 0.03968157729939257\n",
            "312 0.03961718271986043\n",
            "313 0.04200544932575458\n",
            "314 0.042059062085390966\n",
            "315 0.03992577711564183\n",
            "316 0.03916555142278532\n",
            "317 0.04189815999723782\n",
            "318 0.0392160772664668\n",
            "319 0.040961311262416845\n",
            "320 0.03798299015313058\n",
            "321 0.03884069180106154\n",
            "322 0.04093315553724783\n",
            "323 0.039348942769618776\n",
            "324 0.040195114140328086\n",
            "325 0.04248390022628704\n",
            "326 0.03963384492461074\n",
            "327 0.03920810332057376\n",
            "328 0.04027806049666829\n",
            "329 0.039852704780932155\n",
            "330 0.04010567129462386\n",
            "331 0.040900516646124985\n",
            "332 0.04034739992225039\n",
            "333 0.04003633156771308\n",
            "334 0.04118574135477052\n",
            "335 0.040874303546931216\n",
            "336 0.03983303741884452\n",
            "337 0.03995275750766716\n",
            "338 0.03943067514713681\n",
            "339 0.04161181190144198\n",
            "340 0.040305278541116464\n",
            "341 0.041227573961641624\n",
            "342 0.040875015439375335\n",
            "343 0.03950639723308104\n",
            "344 0.039866379589824134\n",
            "345 0.040635595662306005\n",
            "346 0.04001630456487303\n",
            "347 0.04006288017487747\n",
            "348 0.04009854381235947\n",
            "349 0.041020952080368295\n",
            "350 0.03953491231409974\n",
            "351 0.04061294850024523\n",
            "352 0.03956366616024965\n",
            "353 0.03900599461193626\n",
            "354 0.04097626781014971\n",
            "355 0.04022783832563162\n",
            "356 0.039130380310041374\n",
            "357 0.04071561466257521\n",
            "358 0.0410715517280344\n",
            "359 0.04201212071274383\n",
            "360 0.04089332086639191\n",
            "361 0.04045858839320161\n",
            "362 0.03880660954797007\n",
            "363 0.04124279901783517\n",
            "364 0.03921149304559572\n",
            "365 0.040994964540638716\n",
            "366 0.04014346421003743\n",
            "367 0.04050307032606422\n",
            "368 0.040360577054336974\n",
            "369 0.03984542296678537\n",
            "370 0.0401734058013857\n",
            "371 0.04088894578379263\n",
            "372 0.03999891464330912\n",
            "373 0.042494845678537806\n",
            "374 0.03949547266756457\n",
            "375 0.04105171954256068\n",
            "376 0.03970382813051704\n",
            "377 0.04031728612092157\n",
            "378 0.04094485395304725\n",
            "379 0.04202890117272524\n",
            "380 0.039180782782949425\n",
            "381 0.040158286893679694\n",
            "382 0.03820448085726647\n",
            "383 0.03981655479577182\n",
            "384 0.03863117099811303\n",
            "385 0.04049637727959803\n",
            "386 0.04027075284638461\n",
            "387 0.03996231097204727\n",
            "388 0.03943791131021501\n",
            "389 0.0403717536578851\n",
            "390 0.03757490689536324\n",
            "391 0.0406144452015693\n",
            "392 0.04048389046138017\n",
            "393 0.04016443770737424\n",
            "394 0.04168232449066238\n",
            "395 0.04114206539527735\n",
            "396 0.040826736931879964\n",
            "397 0.04069539255655482\n",
            "398 0.041935627756044765\n",
            "399 0.041188411329203145\n",
            "400 0.03872690169752061\n",
            "0 0 20\n",
            "0 0 20\n",
            "0 1 20\n",
            "0 1 20\n",
            "0 2 20\n",
            "0 2 20\n",
            "0 3 20\n",
            "0 3 20\n",
            "0 4 20\n",
            "0 4 20\n",
            "0 5 20\n",
            "0 5 20\n",
            "0 6 20\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-1ad69dcf1840>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mg_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrog_leaping_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_best\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-cc0dde344ed3>\u001b[0m in \u001b[0;36mfrog_leaping_search\u001b[0;34m(docs_vector)\u001b[0m\n\u001b[1;32m     17\u001b[0m                             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemplex_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                 \u001b[0mans_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_worst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_and_worst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_memplex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                 \u001b[0mans_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mans_worst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans_worst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mans_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                     \u001b[0msub_memplex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans_worst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-8842f16a702a>\u001b[0m in \u001b[0;36mcross_over\u001b[0;34m(answer_a, answer_b)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchild1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mchild2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0manswer_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfitness1\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdocs_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcluster_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfitness2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdocs_vector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcluster_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfitness1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mfitness2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-896701497754>\u001b[0m in \u001b[0;36mfitness\u001b[0;34m(answer, docs_vector, size)\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m        )\n\u001b[0;32m----> 8\u001b[0;31m    \u001b[0mwc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m    \u001b[0mbc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_means\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m    \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-73-c8a75393bc3e>\u001b[0m in \u001b[0;36mWC\u001b[0;34m(clusters)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdoc_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mWC\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mSSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mWC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-c8040b53b694>\u001b[0m in \u001b[0;36mSSE\u001b[0;34m(cluster, doc_mean)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msse\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcosin_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-a4ffc103456b>\u001b[0m in \u001b[0;36mcosin_sim\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosin_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mfirst_pass_isfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "g_best, g_value,population = frog_leaping_search(docs_vector)\n",
        "true = 0\n",
        "size = len(dataset.data)\n",
        "print(labels)\n",
        "print(list(g_best))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqf8WOPMKtrqLxIxuqY7vS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}