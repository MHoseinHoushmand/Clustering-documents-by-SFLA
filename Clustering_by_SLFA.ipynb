{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHoseinHoushmand/Clustering_by_SLFA/blob/main/Clustering_by_SLFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305Qb8ysrVGC",
        "outputId": "cd9ccde5-ae43-4a5b-b5da-c847f259b0a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3387 documents - 4 categories\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import pdb\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "categories = [\n",
        "    \"alt.atheism\",\n",
        "    \"talk.religion.misc\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups(\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "\n",
        "labels = dataset.target\n",
        "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
        "true_k = unique_labels.shape[0]\n",
        "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aQkifqukrWjh"
      },
      "outputs": [],
      "source": [
        "\n",
        "def docs_as_tfidf(docs):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "     max_df=0.5,\n",
        "     min_df=5,\n",
        "     stop_words=\"english\",\n",
        "  )\n",
        "\n",
        "  docs_vector = vectorizer.fit_transform(docs)\n",
        "  return docs_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mM9BUN0zrW4l"
      },
      "outputs": [],
      "source": [
        "population_size = 120 # Frogs number\n",
        "memplex_num = 12 #define as m\n",
        "memplex_size = 10 #define as n\n",
        "max_iteration = 50\n",
        "memplex_iteration = 8\n",
        "docs = dataset.data\n",
        "docs_vector = docs_as_tfidf(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sHamQr2PiY8m"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def cosin_sim(a,b):\n",
        "   return cosine_similarity([a], [b])[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k6xqAnE2qko3"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "def SSE(cluster,doc_mean):\n",
        "  size = len(cluster)\n",
        "  sse=0\n",
        "  for doc in cluster:\n",
        "    sse += cosin_sim(doc,doc_mean)**2\n",
        "  sse = sse/size\n",
        "  return sse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YVNRq19JI1GP"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import norm\n",
        "def BC(doc_means):\n",
        "   BC=0\n",
        "   size = len(doc_means)\n",
        "   for i in range(size):\n",
        "      for j in range(i+1,size):\n",
        "          BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "   return BC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "126CwNVcyFge"
      },
      "outputs": [],
      "source": [
        "def WC(clusters):\n",
        "    WC = 0\n",
        "    for cluster in clusters:\n",
        "        doc_mean = np.average(cluster, axis=0)\n",
        "        WC += SSE(cluster,doc_mean)\n",
        "    return WC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "05eFc9zvtYQs"
      },
      "outputs": [],
      "source": [
        "def build_clusters(answer,docs_vector,clusters_size):\n",
        "   clusters = []\n",
        "   for i in range(clusters_size):\n",
        "       clusters.append([])\n",
        "   for j in range(len(answer)):\n",
        "       if -1 < answer[j]:\n",
        "        clusters[answer[j]].append(docs_vector[j])\n",
        "   return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "pYI5dCcj3yS6"
      },
      "outputs": [],
      "source": [
        "def fitness(answer,docs_vector,clusters_size):\n",
        "   doc_means = []\n",
        " #  pdb.runcall(build_clusters,answer,docs_vector,clusters_size)\n",
        "   clusters = build_clusters(answer,docs_vector,clusters_size)\n",
        "   for i in range(clusters_size):\n",
        "       doc_means.append(\n",
        "          np.average(clusters[i], axis=0)\n",
        "       )\n",
        "   wc = WC(clusters)\n",
        "   bc = BC(doc_means)\n",
        "   fitness = wc/bc\n",
        "   return fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "T5yh9899fWW1"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def cross_over(answer_a,answer_b):\n",
        "    size = len(answer_a)\n",
        "    output = []\n",
        "    for i in range(size):\n",
        "       choice = random.choice([0,1])\n",
        "       if choice == 0:\n",
        "          output.append(answer_a[i])\n",
        "       else:\n",
        "          output.append(answer_b[i])\n",
        "    return tuple(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JTWaLgiW0vlX"
      },
      "outputs": [],
      "source": [
        "def best_and_worst(answers):\n",
        "     best =  max(answers, key=answers.get)\n",
        "     worst = min(answers, key=answers.get)\n",
        "     return tuple(best) , tuple(worst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Qhw30ULkdjqq"
      },
      "outputs": [],
      "source": [
        "def global_best(memplexes):\n",
        "     local_bests = {}\n",
        "     for memplex in memplexes:\n",
        "         local_best =  max(memplex, key=memplex.get)\n",
        "         local_bests[local_best]= memplex[local_best]\n",
        "     global_best = max(local_bests, key=local_bests.get)\n",
        "     return global_best, local_bests[global_best]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Qyg18BQwsUiv"
      },
      "outputs": [],
      "source": [
        "def keys_to_remove(keys , dict):\n",
        "   for k in keys:\n",
        "      if k in dict:\n",
        "          dict.pop(k)\n",
        "   return dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wbKSfksRgBsI"
      },
      "outputs": [],
      "source": [
        "def mutation(global_best,clusters_size):\n",
        "    new_ans = list(global_best)\n",
        "    size = int(len(global_best)/4)\n",
        "    indexes = np.random.choice(np.arange(0,len(global_best)), size=size, replace=False)\n",
        "    values= [random.randint(-1, 3) for _ in range(size)]\n",
        "    for i in range(size):\n",
        "      new_ans[indexes[i]] = values[i]\n",
        "    return tuple(new_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hDYtQ87Usvy0"
      },
      "outputs": [],
      "source": [
        "def Create_memplexes(population,memplex_num):\n",
        "     memplexes = []\n",
        "     keys = list(population.keys())\n",
        "     population_size = len(population)\n",
        "     for i in range(memplex_num):\n",
        "         memplexes.append({})\n",
        "     for i in range(population_size):\n",
        "         memplexes[i % memplex_num][keys[i]] = population[keys[i]]\n",
        "     return memplexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vW2U1TK-uLdc"
      },
      "outputs": [],
      "source": [
        "def shufeling(memplexes):\n",
        "    output = {}\n",
        "    for memplex in memplexes:\n",
        "        output.update(memplex)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IesJ9mloCNX1"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "def frog_leaping_search(docs_vector,cluster_size):\n",
        "     answers=np.random.randint(-1, cluster_size, size=(population_size , len(dataset.data)))\n",
        "     population = {}\n",
        "     i=0\n",
        "     for answer in answers:\n",
        "       # pdb.runcall(fitness,answer,docs_vector,cluster_size)\n",
        "        i+=1\n",
        "        population[tuple(answer)] = fitness(answer,docs_vector,cluster_size)\n",
        "        print(i,population[tuple(answer)])\n",
        "\n",
        "     for i in range(max_iteration):\n",
        "        population = dict( sorted(population.items(), key=operator.itemgetter(1), reverse=True))\n",
        "   #    pdb.runcall(Create_memplexes,population, memplex_num)\n",
        "        memplexes = Create_memplexes(population, memplex_num)\n",
        "        population.clear()\n",
        "      #  pdb.set_trace()\n",
        "        for j in range(memplex_num):\n",
        "            print(i,j,len(memplexes[j]))\n",
        "            sub_memplex = dict(random.sample(list(memplexes[j].items()),k=5))\n",
        "            memplexes[j] =  keys_to_remove(sub_memplex.keys(),memplexes[j])\n",
        "            for k in range(memplex_iteration):\n",
        "                #pdb.runcall(best_and_worst,sub_memplex)\n",
        "                ans_best, ans_worst = best_and_worst(sub_memplex)\n",
        "                ans_out = cross_over(ans_best,ans_worst)\n",
        "                fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "\n",
        "              # pdb.runcall(best_and_worst,sub_memplex)\n",
        "               #print(population[ans_worst],population[ans_out])\n",
        "                if (sub_memplex[ans_worst]<fitness_out):\n",
        "                    del sub_memplex[ans_worst]\n",
        "                    sub_memplex[ans_out] = fitness_out\n",
        "                else:\n",
        "                   # pdb.runcall(global_best,memplexes)\n",
        "                    g_best, g_value = global_best(memplexes)\n",
        "                    ans_out = cross_over(g_best,ans_worst)\n",
        "                    fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "                    if (sub_memplex[ans_worst] < fitness_out):\n",
        "                        del sub_memplex[ans_worst]\n",
        "                        sub_memplex[ans_out] = fitness_out\n",
        "                    else:\n",
        "                        del sub_memplex[ans_worst]\n",
        "                     #   pdb.runcall(mutation,g_best,cluster_size)\n",
        "                        ans_out = mutation(g_best,cluster_size)\n",
        "                        fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "                        sub_memplex[ans_out] = fitness_out\n",
        "        #     pdb.runcall(join_dicts,memplexes[j],sub_memplex)\n",
        "            memplexes[j].update(sub_memplex)\n",
        "        g_best, g_value = global_best(memplexes)\n",
        "        print(g_value)\n",
        "        population = shufeling(memplexes)\n",
        "     return g_best, g_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oWUnVZoahHVM",
        "outputId": "ed6390e2-bfb2-4265-801f-4ca0e3de8528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.013740152930011915\n",
            "2 0.014112434424144832\n",
            "3 0.014032940514688319\n",
            "4 0.014047418071981198\n",
            "5 0.014246090940651858\n",
            "6 0.013937872825238597\n",
            "7 0.01391743804524892\n",
            "8 0.013868270777216304\n",
            "9 0.014030279601807537\n",
            "10 0.013862606562598523\n",
            "11 0.014288091658328611\n",
            "12 0.01396469887196816\n",
            "13 0.01397043227520099\n",
            "14 0.013996137063850594\n",
            "15 0.01427795885071379\n",
            "16 0.014051972436403498\n",
            "17 0.014021721839893454\n",
            "18 0.014038251404106828\n",
            "19 0.0138446359742077\n",
            "20 0.013911099610741695\n",
            "21 0.014231945232574596\n",
            "22 0.013890583451439566\n",
            "23 0.013941571263550449\n",
            "24 0.01398139735906956\n",
            "25 0.013886145227611427\n",
            "26 0.013945181900680805\n",
            "27 0.013845319948155927\n",
            "28 0.01388899875129841\n",
            "29 0.01423933035881896\n",
            "30 0.014262926633137305\n",
            "31 0.014126949939349761\n",
            "32 0.01385053077809274\n",
            "33 0.013877038818497904\n",
            "34 0.014133631658684689\n",
            "35 0.013982544682944444\n",
            "36 0.014015828497339422\n",
            "37 0.014087029496031581\n",
            "38 0.013889359875776743\n",
            "39 0.013920944473767217\n",
            "40 0.014071424765643895\n",
            "41 0.014211552781349267\n",
            "42 0.01410707398075283\n",
            "43 0.013826916817992167\n",
            "44 0.014113762454638334\n",
            "45 0.014265077477061482\n",
            "46 0.014013082933169814\n",
            "47 0.014040694669650694\n",
            "48 0.014005071346029433\n",
            "49 0.014003553963500325\n",
            "50 0.014029053278633762\n",
            "51 0.014243721747517686\n",
            "52 0.013849892404588232\n",
            "53 0.01422773326116996\n",
            "54 0.014061263602276133\n",
            "55 0.014062339432589652\n",
            "56 0.01403768182448669\n",
            "57 0.013991987200159676\n",
            "58 0.013937538429168665\n",
            "59 0.013974624459169303\n",
            "60 0.014162227706286312\n",
            "61 0.013945047771702773\n",
            "62 0.01415033262309252\n",
            "63 0.014283160769248123\n",
            "64 0.014026338756544987\n",
            "65 0.01382268880371186\n",
            "66 0.01400475786097233\n",
            "67 0.013732204155880884\n",
            "68 0.013972410044270413\n",
            "69 0.013932778144670982\n",
            "70 0.013970343427790431\n",
            "71 0.014143550048911917\n",
            "72 0.013960213026078052\n",
            "73 0.014145433954416121\n",
            "74 0.014175697916525466\n",
            "75 0.01401896702034595\n",
            "76 0.013889820141394003\n",
            "77 0.013578219840050674\n",
            "78 0.01394974359695619\n",
            "79 0.014027230310370741\n",
            "80 0.013926356975493171\n",
            "81 0.014278152526911387\n",
            "82 0.014018477969998193\n",
            "83 0.014035938652571613\n",
            "84 0.013962101342054048\n",
            "85 0.014082205703582406\n",
            "86 0.01414768179103396\n",
            "87 0.01401877590811143\n",
            "88 0.014299271347009826\n",
            "89 0.013913339289680781\n",
            "90 0.014184019921292366\n",
            "91 0.014145591453292482\n",
            "92 0.014070289010945652\n",
            "93 0.013933964308957247\n",
            "94 0.014163454616232116\n",
            "95 0.013805828123153636\n",
            "96 0.014056315578012492\n",
            "97 0.014137108378325651\n",
            "98 0.014073393773213639\n",
            "99 0.014076089680774253\n",
            "100 0.014135447183021711\n",
            "101 0.014008298526723605\n",
            "102 0.013948365465682231\n",
            "103 0.014203207967822765\n",
            "104 0.014047915426254876\n",
            "105 0.013875785878776949\n",
            "106 0.01403090198613989\n",
            "107 0.014012248639101539\n",
            "108 0.0138858166845849\n",
            "109 0.013893177462502005\n",
            "110 0.013880153984252585\n",
            "111 0.01432183479531154\n",
            "112 0.013763405711051207\n",
            "113 0.014178811598186168\n",
            "114 0.01398499500942052\n",
            "115 0.013841783857832508\n",
            "116 0.014073462214691267\n",
            "117 0.01403927357139466\n",
            "118 0.013933407817148141\n",
            "119 0.013811391047769475\n",
            "120 0.01403325167001728\n",
            "0 0 10\n",
            "0 1 10\n",
            "0 2 10\n",
            "0 3 10\n",
            "0 4 10\n",
            "0 5 10\n",
            "0 6 10\n",
            "0 7 10\n",
            "0 8 10\n",
            "0 9 10\n",
            "0 10 10\n",
            "0 11 10\n",
            "0.014514470043787985\n",
            "1 0 10\n",
            "1 1 10\n",
            "1 2 10\n",
            "1 3 10\n",
            "1 4 10\n",
            "1 5 10\n",
            "1 6 10\n",
            "1 7 10\n",
            "1 8 10\n",
            "1 9 10\n",
            "1 10 10\n",
            "1 11 10\n",
            "0.014515366609551297\n",
            "2 0 10\n",
            "2 1 10\n",
            "2 2 10\n",
            "2 3 10\n",
            "2 4 10\n",
            "2 5 10\n",
            "2 6 10\n",
            "2 7 10\n",
            "2 8 10\n",
            "2 9 10\n",
            "2 10 10\n",
            "2 11 10\n",
            "0.014625329366815352\n",
            "3 0 10\n",
            "3 1 10\n",
            "3 2 10\n",
            "3 3 10\n",
            "3 4 10\n",
            "3 5 10\n",
            "3 6 10\n",
            "3 7 10\n",
            "3 8 10\n",
            "3 9 10\n",
            "3 10 10\n",
            "3 11 10\n",
            "0.014796768702118964\n",
            "4 0 10\n",
            "4 1 10\n",
            "4 2 10\n",
            "4 3 10\n",
            "4 4 10\n",
            "4 5 10\n",
            "4 6 10\n",
            "4 7 10\n",
            "4 8 10\n",
            "4 9 10\n",
            "4 10 10\n",
            "4 11 10\n",
            "0.014935313498087585\n",
            "5 0 10\n",
            "5 1 10\n",
            "5 2 10\n",
            "5 3 10\n",
            "5 4 10\n",
            "5 5 10\n",
            "5 6 10\n",
            "5 7 10\n",
            "5 8 10\n",
            "5 9 10\n",
            "5 10 10\n",
            "5 11 10\n",
            "0.014963667785840188\n",
            "6 0 10\n",
            "6 1 10\n",
            "6 2 10\n",
            "6 3 10\n",
            "6 4 10\n",
            "6 5 10\n",
            "6 6 10\n",
            "6 7 10\n",
            "6 8 10\n",
            "6 9 10\n",
            "6 10 10\n",
            "6 11 10\n",
            "0.015028657339330335\n",
            "7 0 10\n",
            "7 1 10\n",
            "7 2 10\n",
            "7 3 10\n",
            "7 4 10\n",
            "7 5 10\n",
            "7 6 10\n",
            "7 7 10\n",
            "7 8 10\n",
            "7 9 10\n",
            "7 10 10\n",
            "7 11 10\n",
            "0.01522654664472141\n",
            "8 0 10\n",
            "8 1 10\n",
            "8 2 10\n",
            "8 3 10\n",
            "8 4 10\n",
            "8 5 10\n",
            "8 6 10\n",
            "8 7 10\n",
            "8 8 10\n",
            "8 9 10\n",
            "8 10 10\n",
            "8 11 10\n",
            "0.01533064538063788\n",
            "9 0 10\n",
            "9 1 10\n",
            "9 2 10\n",
            "9 3 10\n",
            "9 4 10\n",
            "9 5 10\n",
            "9 6 10\n",
            "9 7 10\n",
            "9 8 10\n",
            "9 9 10\n",
            "9 10 10\n",
            "9 11 10\n",
            "0.015622616929904558\n",
            "10 0 10\n",
            "10 1 10\n",
            "10 2 10\n",
            "10 3 10\n",
            "10 4 10\n",
            "10 5 10\n",
            "10 6 10\n",
            "10 7 10\n",
            "10 8 10\n",
            "10 9 10\n",
            "10 10 10\n",
            "10 11 10\n",
            "0.015622616929904558\n",
            "11 0 10\n",
            "11 1 10\n",
            "11 2 10\n",
            "11 3 10\n",
            "11 4 10\n",
            "11 5 10\n",
            "11 6 10\n",
            "11 7 10\n",
            "11 8 10\n",
            "11 9 10\n",
            "11 10 10\n",
            "11 11 10\n",
            "0.015966160418267632\n",
            "12 0 10\n",
            "12 1 10\n",
            "12 2 10\n",
            "12 3 10\n",
            "12 4 10\n",
            "12 5 10\n",
            "12 6 10\n",
            "12 7 10\n",
            "12 8 10\n",
            "12 9 10\n",
            "12 10 10\n",
            "12 11 10\n",
            "0.015977478610882466\n",
            "13 0 10\n",
            "13 1 10\n",
            "13 2 10\n",
            "13 3 10\n",
            "13 4 10\n",
            "13 5 10\n",
            "13 6 10\n",
            "13 7 10\n",
            "13 8 10\n",
            "13 9 10\n",
            "13 10 10\n",
            "13 11 10\n",
            "0.016182915663029356\n",
            "14 0 10\n",
            "14 1 10\n",
            "14 2 10\n",
            "14 3 10\n",
            "14 4 10\n",
            "14 5 10\n",
            "14 6 10\n",
            "14 7 10\n",
            "14 8 10\n",
            "14 9 10\n",
            "14 10 10\n",
            "14 11 10\n",
            "0.016182915663029356\n",
            "15 0 10\n",
            "15 1 10\n",
            "15 2 10\n",
            "15 3 10\n",
            "15 4 10\n",
            "15 5 10\n",
            "15 6 10\n",
            "15 7 10\n",
            "15 8 10\n",
            "15 9 10\n",
            "15 10 10\n",
            "15 11 10\n",
            "0.01633231433647352\n",
            "16 0 10\n",
            "16 1 10\n",
            "16 2 10\n",
            "16 3 10\n",
            "16 4 10\n",
            "16 5 10\n",
            "16 6 10\n",
            "16 7 10\n",
            "16 8 10\n",
            "16 9 10\n",
            "16 10 10\n",
            "16 11 10\n",
            "0.016429935561987914\n",
            "17 0 10\n",
            "17 1 10\n",
            "17 2 10\n",
            "17 3 10\n",
            "17 4 10\n",
            "17 5 10\n",
            "17 6 10\n",
            "17 7 10\n",
            "17 8 10\n",
            "17 9 10\n",
            "17 10 10\n",
            "17 11 10\n",
            "0.016569343594696473\n",
            "18 0 10\n",
            "18 1 10\n",
            "18 2 10\n",
            "18 3 10\n",
            "18 4 10\n",
            "18 5 10\n",
            "18 6 10\n",
            "18 7 10\n",
            "18 8 10\n",
            "18 9 10\n",
            "18 10 10\n",
            "18 11 10\n",
            "0.016761528661922515\n",
            "19 0 10\n",
            "19 1 10\n",
            "19 2 10\n",
            "19 3 10\n",
            "19 4 10\n",
            "19 5 10\n",
            "19 6 10\n",
            "19 7 10\n",
            "19 8 10\n",
            "19 9 10\n",
            "19 10 10\n",
            "19 11 10\n",
            "0.017155265551031588\n",
            "20 0 10\n",
            "20 1 10\n",
            "20 2 10\n",
            "20 3 10\n",
            "20 4 10\n",
            "20 5 10\n",
            "20 6 10\n",
            "20 7 10\n",
            "20 8 10\n",
            "20 9 10\n",
            "20 10 10\n",
            "20 11 10\n",
            "0.017155265551031588\n",
            "21 0 10\n",
            "21 1 10\n",
            "21 2 10\n",
            "21 3 10\n",
            "21 4 10\n",
            "21 5 10\n",
            "21 6 10\n",
            "21 7 10\n",
            "21 8 10\n",
            "21 9 10\n",
            "21 10 10\n",
            "21 11 10\n",
            "0.017155265551031588\n",
            "22 0 10\n",
            "22 1 10\n",
            "22 2 10\n",
            "22 3 10\n",
            "22 4 10\n",
            "22 5 10\n",
            "22 6 10\n",
            "22 7 10\n",
            "22 8 10\n",
            "22 9 10\n",
            "22 10 10\n",
            "22 11 10\n",
            "0.01736399149083563\n",
            "23 0 10\n",
            "23 1 10\n",
            "23 2 10\n",
            "23 3 10\n",
            "23 4 10\n",
            "23 5 10\n",
            "23 6 10\n",
            "23 7 10\n",
            "23 8 10\n",
            "23 9 10\n",
            "23 10 10\n",
            "23 11 10\n",
            "0.01762477996553092\n",
            "24 0 10\n",
            "24 1 10\n",
            "24 2 10\n",
            "24 3 10\n",
            "24 4 10\n",
            "24 5 10\n",
            "24 6 10\n",
            "24 7 10\n",
            "24 8 10\n",
            "24 9 10\n",
            "24 10 10\n",
            "24 11 10\n",
            "0.017742479988442666\n",
            "25 0 10\n",
            "25 1 10\n",
            "25 2 10\n",
            "25 3 10\n",
            "25 4 10\n",
            "25 5 10\n",
            "25 6 10\n",
            "25 7 10\n",
            "25 8 10\n",
            "25 9 10\n",
            "25 10 10\n",
            "25 11 10\n",
            "0.017950476366348958\n",
            "26 0 10\n",
            "26 1 10\n",
            "26 2 10\n",
            "26 3 10\n",
            "26 4 10\n",
            "26 5 10\n",
            "26 6 10\n",
            "26 7 10\n",
            "26 8 10\n",
            "26 9 10\n",
            "26 10 10\n",
            "26 11 10\n",
            "0.017950476366348958\n",
            "27 0 10\n",
            "27 1 10\n",
            "27 2 10\n",
            "27 3 10\n",
            "27 4 10\n",
            "27 5 10\n",
            "27 6 10\n",
            "27 7 10\n",
            "27 8 10\n",
            "27 9 10\n",
            "27 10 10\n",
            "27 11 10\n",
            "0.018296617245831526\n",
            "28 0 10\n",
            "28 1 10\n",
            "28 2 10\n",
            "28 3 10\n",
            "28 4 10\n",
            "28 5 10\n",
            "28 6 10\n",
            "28 7 10\n",
            "28 8 10\n",
            "28 9 10\n",
            "28 10 10\n",
            "28 11 10\n",
            "0.01829784015953067\n",
            "29 0 10\n",
            "29 1 10\n",
            "29 2 10\n",
            "29 3 10\n",
            "29 4 10\n",
            "29 5 10\n",
            "29 6 10\n",
            "29 7 10\n",
            "29 8 10\n",
            "29 9 10\n",
            "29 10 10\n",
            "29 11 10\n",
            "0.018407589082005727\n",
            "30 0 10\n",
            "30 1 10\n",
            "30 2 10\n",
            "30 3 10\n",
            "30 4 10\n",
            "30 5 10\n",
            "30 6 10\n",
            "30 7 10\n",
            "30 8 10\n",
            "30 9 10\n",
            "30 10 10\n",
            "30 11 10\n",
            "0.01872740718436457\n",
            "31 0 10\n",
            "31 1 10\n",
            "31 2 10\n",
            "31 3 10\n",
            "31 4 10\n",
            "31 5 10\n",
            "31 6 10\n",
            "31 7 10\n",
            "31 8 10\n",
            "31 9 10\n",
            "31 10 10\n",
            "31 11 10\n",
            "0.01872740718436457\n",
            "32 0 10\n",
            "32 1 10\n",
            "32 2 10\n",
            "32 3 10\n",
            "32 4 10\n",
            "32 5 10\n",
            "32 6 10\n",
            "32 7 10\n",
            "32 8 10\n",
            "32 9 10\n",
            "32 10 10\n",
            "32 11 10\n",
            "0.018901225797482282\n",
            "33 0 10\n",
            "33 1 10\n",
            "33 2 10\n",
            "33 3 10\n",
            "33 4 10\n",
            "33 5 10\n",
            "33 6 10\n",
            "33 7 10\n",
            "33 8 10\n",
            "33 9 10\n",
            "33 10 10\n",
            "33 11 10\n",
            "0.019159012026337748\n",
            "34 0 10\n",
            "34 1 10\n",
            "34 2 10\n",
            "34 3 10\n",
            "34 4 10\n",
            "34 5 10\n",
            "34 6 10\n",
            "34 7 10\n",
            "34 8 10\n",
            "34 9 10\n",
            "34 10 10\n",
            "34 11 10\n",
            "0.019159012026337748\n",
            "35 0 10\n",
            "35 1 10\n",
            "35 2 10\n",
            "35 3 10\n",
            "35 4 10\n",
            "35 5 10\n",
            "35 6 10\n",
            "35 7 10\n",
            "35 8 10\n",
            "35 9 10\n",
            "35 10 10\n",
            "35 11 10\n",
            "0.019283749241370454\n",
            "36 0 10\n",
            "36 1 10\n",
            "36 2 10\n",
            "36 3 10\n",
            "36 4 10\n",
            "36 5 10\n",
            "36 6 10\n",
            "36 7 10\n",
            "36 8 10\n",
            "36 9 10\n",
            "36 10 10\n",
            "36 11 10\n",
            "0.01947908786468673\n",
            "37 0 10\n",
            "37 1 10\n",
            "37 2 10\n",
            "37 3 10\n",
            "37 4 10\n",
            "37 5 10\n",
            "37 6 10\n",
            "37 7 10\n",
            "37 8 10\n",
            "37 9 10\n",
            "37 10 10\n",
            "37 11 10\n",
            "0.019573640931007635\n",
            "38 0 10\n",
            "38 1 10\n",
            "38 2 10\n",
            "38 3 10\n",
            "38 4 10\n",
            "38 5 10\n",
            "38 6 10\n",
            "38 7 10\n",
            "38 8 10\n",
            "38 9 10\n",
            "38 10 10\n",
            "38 11 10\n",
            "0.019673759442584787\n",
            "39 0 10\n",
            "39 1 10\n",
            "39 2 10\n",
            "39 3 10\n",
            "39 4 10\n",
            "39 5 10\n",
            "39 6 10\n",
            "39 7 10\n",
            "39 8 10\n",
            "39 9 10\n",
            "39 10 10\n",
            "39 11 10\n",
            "0.01974322457456094\n",
            "40 0 10\n",
            "40 1 10\n",
            "40 2 10\n",
            "40 3 10\n",
            "40 4 10\n",
            "40 5 10\n",
            "40 6 10\n",
            "40 7 10\n",
            "40 8 10\n",
            "40 9 10\n",
            "40 10 10\n",
            "40 11 10\n",
            "0.01986583940320444\n",
            "41 0 10\n",
            "41 1 10\n",
            "41 2 10\n",
            "41 3 10\n",
            "41 4 10\n",
            "41 5 10\n",
            "41 6 10\n",
            "41 7 10\n",
            "41 8 10\n",
            "41 9 10\n",
            "41 10 10\n",
            "41 11 10\n",
            "0.019950727131017327\n",
            "42 0 10\n",
            "42 1 10\n",
            "42 2 10\n",
            "42 3 10\n",
            "42 4 10\n",
            "42 5 10\n",
            "42 6 10\n",
            "42 7 10\n",
            "42 8 10\n",
            "42 9 10\n",
            "42 10 10\n",
            "42 11 10\n",
            "0.020133625298775035\n",
            "43 0 10\n",
            "43 1 10\n",
            "43 2 10\n",
            "43 3 10\n",
            "43 4 10\n",
            "43 5 10\n",
            "43 6 10\n",
            "43 7 10\n",
            "43 8 10\n",
            "43 9 10\n",
            "43 10 10\n",
            "43 11 10\n",
            "0.02024594274662036\n",
            "44 0 10\n",
            "44 1 10\n",
            "44 2 10\n",
            "44 3 10\n",
            "44 4 10\n",
            "44 5 10\n",
            "44 6 10\n",
            "44 7 10\n",
            "44 8 10\n",
            "44 9 10\n",
            "44 10 10\n",
            "44 11 10\n",
            "0.020343779812387962\n",
            "45 0 10\n",
            "45 1 10\n",
            "45 2 10\n",
            "45 3 10\n",
            "45 4 10\n",
            "45 5 10\n",
            "45 6 10\n",
            "45 7 10\n",
            "45 8 10\n",
            "45 9 10\n",
            "45 10 10\n",
            "45 11 10\n",
            "0.020400849237008824\n",
            "46 0 10\n",
            "46 1 10\n",
            "46 2 10\n",
            "46 3 10\n",
            "46 4 10\n",
            "46 5 10\n",
            "46 6 10\n",
            "46 7 10\n",
            "46 8 10\n",
            "46 9 10\n",
            "46 10 10\n",
            "46 11 10\n",
            "0.02062822592434518\n",
            "47 0 10\n",
            "47 1 10\n",
            "47 2 10\n",
            "47 3 10\n",
            "47 4 10\n",
            "47 5 10\n",
            "47 6 10\n",
            "47 7 10\n",
            "47 8 10\n",
            "47 9 10\n",
            "47 10 10\n",
            "47 11 10\n",
            "0.020794010716213264\n",
            "48 0 10\n",
            "48 1 10\n",
            "48 2 10\n",
            "48 3 10\n",
            "48 4 10\n",
            "48 5 10\n",
            "48 6 10\n",
            "48 7 10\n",
            "48 8 10\n",
            "48 9 10\n",
            "48 10 10\n",
            "48 11 10\n",
            "0.020797359975847307\n",
            "49 0 10\n",
            "49 1 10\n",
            "49 2 10\n",
            "49 3 10\n",
            "49 4 10\n",
            "49 5 10\n",
            "49 6 10\n",
            "49 7 10\n",
            "49 8 10\n",
            "49 9 10\n",
            "49 10 10\n",
            "49 11 10\n",
            "0.020858244961336807\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-45013a136d64>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mg_best\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mtrue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
          ]
        }
      ],
      "source": [
        "g_best, g_value = frog_leaping_search(docs_vector,4)\n",
        "true = 0\n",
        "size = len(dataset.data)\n",
        "for i in size:\n",
        "   if labels[i] == g_best[i]:\n",
        "      true = true +1\n",
        "print(true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2EO8Mnvwdk8"
      },
      "outputs": [],
      "source": [
        "uniqueList=[[3,2,1,3],[5,3,2,1],[3,8,5,9],[2,6,4,9]]\n",
        "\n",
        "print(random.sample(uniqueList, 2))\n",
        "\n",
        "a= {'s':3,'4':6,'sdgfsdfg':656}\n",
        "b= max(a.values())\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EjE0xIlKoqL"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "x = {'4':7,'8':2,'99':45}\n",
        "x = dict( sorted(x.items(), key=operator.itemgetter(1), reverse=True))\n",
        "print (x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUgFFjyU9ubi"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKto2zx7pJL3"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# تعیین بازه مقداری\n",
        "\n",
        "import pdb\n",
        "beeeeee =46363\n",
        "zee={'ddd':2352}\n",
        "for i in range(1):\n",
        "  # pdb.set_trace()\n",
        "   array = np.random.choice(np.arange(-1, 10), size=5, replace=False)\n",
        "   print(array)\n",
        "\n",
        "ggggga=643\n",
        "print('nali')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF9-RO75Vbux"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "random_numbers = [random.randint(1, 100) for _ in range(10)]\n",
        "print(random_numbers)\n",
        "my_dict = {'a': 1.235, 'b': 2.23525235, 'c': 3.235223523, 'd': 4.235235235, 'e': 5.23525252323}\n",
        "\n",
        "del my_dict[['a','b']]\n",
        "random_objects = random.sample(list(my_dict.items()), k=3)\n",
        "print(random_objects)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPzTsVCKkaFvha1xEi92LZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}