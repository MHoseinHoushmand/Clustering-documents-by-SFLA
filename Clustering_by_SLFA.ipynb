{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHp+DoQkCwK7h7SUTLv9PV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHoseinHoushmand/Clustering_by_SLFA/blob/main/Clustering_by_SLFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305Qb8ysrVGC",
        "outputId": "db9b0733-d9df-4c44-f091-eaf8db4b94d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3387 documents - 4 categories\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "categories = [\n",
        "    \"alt.atheism\",\n",
        "    \"talk.religion.misc\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups(\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "\n",
        "labels = dataset.target\n",
        "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
        "true_k = unique_labels.shape[0]\n",
        "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def docs_as_tfidf(docs):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "     max_df=0.5,\n",
        "     min_df=5,\n",
        "     stop_words=\"english\",\n",
        "  )\n",
        "  docs_vector = vectorizer.fit_transform(docs)\n",
        "  return docs_vector.toarray()\n",
        "\n"
      ],
      "metadata": {
        "id": "aQkifqukrWjh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = 120 # Frogs number\n",
        "memplex_num = 12 #define as m\n",
        "memplex_size = 10 #define as n\n",
        "max_iteration = 50\n",
        "memplex_iteration = 8\n",
        "docs = dataset.data\n",
        "docs_vector = docs_as_tfidf(docs)"
      ],
      "metadata": {
        "id": "mM9BUN0zrW4l"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosin_sim(a,b):\n",
        "   return np.dot(a,b)/(norm(a)*norm(b))"
      ],
      "metadata": {
        "id": "sHamQr2PiY8m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "def SSE(cluster,docs_vector):\n",
        "  size = len(cluster)\n",
        "  SSE=0\n",
        "  meandoc = np.average(docs_vector,axis=0)\n",
        "  for doc in cluster:\n",
        "    SSE += cosin_sim(doc,meandoc)**2\n",
        "  SSE = SSE/size\n",
        "  return SSE"
      ],
      "metadata": {
        "id": "k6xqAnE2qko3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "def BC(doc_means):\n",
        "   BC=0\n",
        "   size = len(doc_means)\n",
        "   for i in range(size):\n",
        "      for j in range(i+1,size):\n",
        "          BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "   return BC"
      ],
      "metadata": {
        "id": "YVNRq19JI1GP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WC(clusters,docs_vector):\n",
        "    WC = 0\n",
        "    for cluster in clusters:\n",
        "        WC += SSE(cluster,docs_vector)\n",
        "    return WC\n"
      ],
      "metadata": {
        "id": "126CwNVcyFge"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_clusters(answer,docs_vector,clusters_size):\n",
        "   clusters = []\n",
        "   for i in range(clusters_size):\n",
        "       curent_cluster = []\n",
        "       for j in answer:\n",
        "          if i == answer[j]:\n",
        "             curent_cluster.append(docs_vector[j])\n",
        "       clusters.append(curent_cluster)\n",
        "   return clusters"
      ],
      "metadata": {
        "id": "05eFc9zvtYQs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(answer,docs_vector,clusters_size):\n",
        "   doc_means = []\n",
        "   clusters = build_clusters(answer,docs_vector,clusters_size)\n",
        "   for i in range(clusters_size):\n",
        "       doc_means.append(\n",
        "          np.average(clusters[i], axis=0)\n",
        "       )\n",
        "   fitness = WC(clusters,docs_vector)/BC(doc_means)\n"
      ],
      "metadata": {
        "id": "pYI5dCcj3yS6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def cross_over(answer_a,answer_b):\n",
        "    size = len(answer_a)\n",
        "    output = np.array(())\n",
        "    for i in range(size):\n",
        "       choice = random.choice([0,1])\n",
        "       if choice == 0:\n",
        "          np.append(output,answer_a[i])\n",
        "       else:\n",
        "          np.append(output,answer_b[i])\n",
        "    return output"
      ],
      "metadata": {
        "id": "T5yh9899fWW1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_and_worst(answers,fitness_dict):\n",
        "     temp ={}\n",
        "     for answer in answers:\n",
        "        temp[tuple(answer)] = fitness_dict[tuple(answer)]\n",
        "     best =  max(temp, key=temp.get)\n",
        "     worst = min(temp, key=temp.get)\n",
        "     return np.array(best) ,np.array(worst)"
      ],
      "metadata": {
        "id": "JTWaLgiW0vlX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def global_best(answers,fitness_dict):\n",
        "     temp ={}\n",
        "     for answer in answers:\n",
        "        temp[tuple(answer)] = fitness_dict[tuple(answer)]\n",
        "     best =  max(temp, key=temp.get)\n",
        "     return np.array(best), temp[tuple(best)]"
      ],
      "metadata": {
        "id": "Qhw30ULkdjqq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutation(global_best,clusters_size):\n",
        "    new_ans = global_best\n",
        "    size = len(global_best)/4\n",
        "    array = np.random.choice(np.arange(-1,clusters_size), size=size, replace=False)\n",
        "    for i in array:\n",
        "      new_ans = new_ans[i]\n",
        "    return new_ans"
      ],
      "metadata": {
        "id": "wbKSfksRgBsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_memplexes(population,memplex_num):\n",
        "     memplexes = {}\n",
        "     population_size = len(population)\n",
        "     for i in range(memplex_num):\n",
        "         memplexes[i] = []\n",
        "     for i in population_size:\n",
        "         memplexes[i % memplex_num].append(population[i])\n",
        "     return memplexes\n"
      ],
      "metadata": {
        "id": "hDYtQ87Usvy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "def frog_leaping_search(docs_vector,cluster_size):\n",
        "     answers=np.random.randint(-1, cluster_size, size=(population_size , len(dataset.data)))\n",
        "     population = {}\n",
        "     for answer in answers:\n",
        "        population[tuple(answer)] = fitness(answer,docs_vector,cluster_size)\n",
        "     population = dict( sorted(population.items(), key=operator.itemgetter(1), reverse=True))\n",
        "     memplexes = Create_memplexes(population, memplex_num)\n",
        "\n",
        "     for i in range(max_iteration):\n",
        "         for j in range(memplex_num):\n",
        "            sub_memplex = random.sample(memplexes[j],memplex_size/2)\n",
        "            for k in range(memplex_iteration):\n",
        "               ans_best, ans_worst = best_and_worst(sub_memplex,fitness_dict)\n",
        "               ans_out = cross_over(ans_best,ans_worst)\n",
        "               if (fitness_dict[tuple(ans_worst)]<fitness_dict[tuple(ans_out)]):\n",
        "                    np.delete(sub_memplex, ans_worst)\n",
        "                    np.add(sub_memplex,ans_out)\n",
        "               else:\n",
        "                    g_best, g_value = global_best(population,fitness_dict)\n",
        "                    ans_out = cross_over(g_best,ans_worst)\n",
        "                    if (fitness_dict[tuple(ans_worst)]<fitness_dict[tuple(ans_out)]):\n",
        "                        np.delete(sub_memplex, ans_worst)\n",
        "                        np.add(sub_memplex,ans_out)\n",
        "                    else:\n",
        "                        ans_out = mutation(global_best,cluster_size)\n",
        "                        np.delete(sub_memplex, ans_worst)\n",
        "                        np.add(sub_memplex,ans_out)\n",
        "               fitness_dict[tuple(ans_out)] = fitness(ans_out,docs_vector,cluster_size)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IesJ9mloCNX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniqueList=[[3,2,1,3],[5,3,2,1],[3,8,5,9],[2,6,4,9]]\n",
        "\n",
        "print(random.sample(uniqueList, 2))\n",
        "\n",
        "a= {'s':3,'4':6,'sdgfsdfg':656}\n",
        "b= max(a.values())\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2EO8Mnvwdk8",
        "outputId": "d9b6b62c-313c-41f3-859a-857e5fbe6542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 3, 2, 1], [2, 6, 4, 9]]\n",
            "656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "x = {'4':7,'8':2,'99':45}\n",
        "x = dict( sorted(x.items(), key=operator.itemgetter(1), reverse=True))\n",
        "print (x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EjE0xIlKoqL",
        "outputId": "d6b6c791-8c3c-436c-ccb1-9bf94eee5a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'99': 45, '4': 7, '8': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# تعیین بازه مقداری\n",
        "\n",
        "\n",
        "array = np.random.choice(np.arange(-1, 10), size=5, replace=False)\n",
        "\n",
        "print(array)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CmX4ivo9nk3",
        "outputId": "4a188933-4a58-4bc3-e6da-ecb1e08ef56f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 6 9 2 1]\n"
          ]
        }
      ]
    }
  ]
}