{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHoseinHoushmand/Clustering_by_SLFA/blob/main/Clustering_by_SLFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ovHcWlfr8Ao9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from numpy.linalg import norm\n",
        "import operator\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e2J1TujL22H1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f2f5b6f-59a3-42a8-c1d9-97c730c1bc45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3758 documents - 4 categories\n",
            "[3 2 0 0 1 1 2 3 2 1 3 1 3 0 0 2 1 0 3 1 0 2 1 0 2 2 1 1 3 3 0 1 1 2 3 3 2\n",
            " 1 1 1 2 1 2 3 2 0 0 2 2 1 3 0 1 2 2 3 1 0 1 2 0 1 3 1 3 2 0 3 1 1 0 3 3 0\n",
            " 1 0 2 0 2 1 2 2 0 2 3 2 1 2 0 2 0 1 1 3 3 2 0 2 0 3 1 0 0 1 2 3 3 0 3 3 2\n",
            " 1 0 0 1 3 2 2 1 2 2 0 2 3 2 1 0 1 2 3 2 2 2 3 3 0 3 3 0 0 2 0 1 3 1 2 1 1\n",
            " 3 2 3 3 0 1 3 3 2 2 2 3 2 0 2 0 1 3 3 1 0 2 2 2 2 3 2 3 1 1 1 1 2 3 3 1 2\n",
            " 1 1 2 3 1 0 2 2 2 0 2 3 3 2 1 1 0 3 2 0 3 2 3 0 2 3 3 0 1 3 1 0 3 0 0 2 3\n",
            " 3 3 1 1 1 3 1 0 3 1 0 3 2 3 3 0 0 1 1 3 2 2 2 1 3 0 2 3 3 0 1 3 2 0 3 2 0\n",
            " 0 0 1 2 3 3 3 3 2 1 3 2 2 2 1 0 3 2 2 3 0 3 2 1 0 2 1 2 2 2 0 2 2 2 1 2 3\n",
            " 0 0 3 2 3 0 3 3 0 0 0 0 0 0 2 0 2 3 3 3 3 0 3 0 3 2 1 3 1 2 2 0 3 0 1 1 1\n",
            " 1 2 2 3 1 1 2 0 0 3 1 0 1 1 2 1 3 3 3 3 2 2 3 1 3 1 0 0 0 2 3 2 2 1 0 1 1\n",
            " 2 0 3 3 3 3 1 0 0 0 3 2 2 1 2 2 0 1 3 3 3 1 2 0 2 1 1 1 2 3 3 3 0 1 1 0 3\n",
            " 2 1 3 3 0 3 2 2 3 3 2 2 1 1 2 2 3 2 0 3 0 3 2 3 1 3 3 1 1 0 2 1 1 3 0 2 0\n",
            " 3 3 3 2 1 2 3 1 2 3 3 1 1 1 3 3 1 3 2 2 0 1 2 2 1 0 0 3 1 1 1 1 1 3 1 3 1\n",
            " 2 3 3 2 0 1 2 3 3 0 3 0 3 0 3 2 0 3 2]\n"
          ]
        }
      ],
      "source": [
        "categories = [  #Select 4 categories from fetch_20newsgroups dataset\n",
        "    \"alt.atheism\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "    \"rec.sport.hockey\",\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups( #Preprocessing before using dataset\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "labels = dataset.target[0:500]\n",
        "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
        "true_k = unique_labels.shape[0]\n",
        "print(f\"{len(dataset.data)} documents - {true_k} categories\")\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ERPNfqNYATbl"
      },
      "outputs": [],
      "source": [
        "# Vectorize all document as their term frequency(tfidf score)\n",
        "def docs_as_tfidf(docs):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "     max_df=0.5, #Removing terms that are used in more than 50% of articles\n",
        "     min_df=5,   #Removing terms that are not used in less than 10 of articles\n",
        "     stop_words=\"english\",\n",
        "     #  max_features=1000,\n",
        "  )\n",
        "  docs_vector = vectorizer.fit_transform(docs)\n",
        "  print(len(docs_vector.toarray()[0]))\n",
        "  return docs_vector.toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5Y_4pWLVAZIh"
      },
      "outputs": [],
      "source": [
        "def cosin_sim(a,b):\n",
        "   return cosine_similarity([a], [b])[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Object oriented Format**"
      ],
      "metadata": {
        "id": "KXZlGPk58X8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Cluster:\n",
        "     def __init__(self):\n",
        "         self.documents = []\n",
        "         self.doc_mean = []\n",
        "\n",
        "     def get_doc_mean(self):\n",
        "        self.doc_mean = np.average(self.documents, axis=0)\n",
        "        return self.doc_mean\n",
        "\n",
        "     def SSE(self):     #Sum of squared error(SSE) as similarity of each documents with the cluster mean in document\n",
        "         doc_mean = self.get_doc_mean()\n",
        "         size = len(self.documents)\n",
        "         sse=0\n",
        "         for doc in self.documents:\n",
        "             sse += cosin_sim(doc,doc_mean)**2\n",
        "         sse = sse/size\n",
        "         return sse"
      ],
      "metadata": {
        "id": "iBMKJt5lzl3W"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Frog:\n",
        "     def __init__(self,answer,docs_vector,n_clusters):\n",
        "        self.answer = answer\n",
        "        self.value = self.fitness(docs_vector,n_clusters)\n",
        "\n",
        "\n",
        "\n",
        "     def build_clusters(self,docs_vector,n_clusters):#Build clusters for frog\n",
        "          clusters = []\n",
        "          for i in range(n_clusters):\n",
        "             cluster = Cluster()\n",
        "             clusters.append(cluster)\n",
        "          for j in range(len(self.answer)):\n",
        "             if -1 < self.answer[j]:\n",
        "                clusters[self.answer[j]].documents.append(docs_vector[j])\n",
        "          return clusters\n",
        "\n",
        "\n",
        "     def WC(self,clusters):   #Calculate similarity within clusters\n",
        "        WC = 0\n",
        "        for cluster in clusters:\n",
        "            WC += cluster.SSE()\n",
        "        return WC\n",
        "\n",
        "\n",
        "     def BC(self,doc_means):#Calculate similarity between clusters\n",
        "          BC=0\n",
        "          size = len(doc_means)\n",
        "          for i in range(size):\n",
        "              for j in range(i+1,size):\n",
        "                  BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "          return BC\n",
        "\n",
        "\n",
        "     def fitness(self,docs_vector,n_clusters):\n",
        "           doc_means = []\n",
        "          # pdb.set_trace()\n",
        "           clusters = self.build_clusters(docs_vector,n_clusters)\n",
        "           for i in range(n_clusters):\n",
        "               doc_means.append(\n",
        "                  clusters[i].get_doc_mean()\n",
        "               )\n",
        "           wc = self.WC(clusters) #Calculate similarity within clusters\n",
        "           bc = self.BC(doc_means) #Calculate similarity between clusters\n",
        "           fitness = wc/bc\n",
        "           return fitness\n",
        "\n",
        "\n",
        "     def cross_over(self,frog_b,docs_vector,n_clusters): #perform 2 points cross over\n",
        "           frog_size = len(self.answer)\n",
        "           points = sorted(np.random.choice(np.arange(0,frog_size), size=2, replace=False))\n",
        "           answer1 = self.answer[:points[0]] + frog_b.answer[points[0]:points[1]] + self.answer[points[1]:]\n",
        "           answer2 = frog_b.answer[:points[0]] + self.answer[points[0]:points[1]] + frog_b.answer[points[1]:]\n",
        "           child1 = Frog(answer1,docs_vector,n_clusters)\n",
        "           child2 = Frog(answer2,docs_vector,n_clusters)\n",
        "           if child1.value > child2.value: # return best child\n",
        "               return child1\n",
        "           else :\n",
        "               return child2\n",
        "\n",
        "     def mutation(self,docs_vector,n_clusters):#Select len(answer)/4 of answers and change value\n",
        "         new_ans = list(self.answer)\n",
        "         size = int(len(self.answer)/4)\n",
        "         indexes = np.random.choice(np.arange(0,len(self.answer)), size=size, replace=False)\n",
        "         values= [random.randint(0, 3) for _ in range(size)]\n",
        "         for i in range(size):\n",
        "            new_ans[indexes[i]] = values[i]\n",
        "         child = Frog(tuple(new_ans),docs_vector,n_clusters)\n",
        "         return  child"
      ],
      "metadata": {
        "id": "cVyGX4nWmhKz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Memplex:\n",
        "     def __init__(self):\n",
        "         self.frogs = []\n",
        "\n",
        "     def best(self):\n",
        "        if len(self.frogs) > 0:\n",
        "           return self.frogs[0]\n",
        "\n",
        "     def worst(self,frogs):\n",
        "        if len(self.frogs) > 0:\n",
        "           return self.frogs[len(self.frogs)-1]\n",
        "\n",
        "     def frogs_to_remove(self,sub_memplex):\n",
        "         for item in sub_memplex.frogs:\n",
        "            self.frogs.remove(item)\n",
        "         return self\n",
        "\n",
        "     def add_frogs(self,submemplex):\n",
        "         self.frogs = self.frogs + submemplex.frogs"
      ],
      "metadata": {
        "id": "CL-MOSXd5xjg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Submemplex:\n",
        "     def __init__(self, memplex ,n_submemplex,memplex_size ):\n",
        "         self.frogs = []\n",
        "         self.prob_list = []\n",
        "         keys = []\n",
        "         for i in range(memplex_size):\n",
        "             for j in range(2*(memplex_size-i)):\n",
        "                 self.prob_list.append(i)\n",
        "         k=0\n",
        "         while(k!=n_submemplex):\n",
        "            index = random.choice(self.prob_list)\n",
        "            key = memplex.frogs[index].answer\n",
        "           # pdb.set_trace()\n",
        "            if key not in keys:\n",
        "                self.frogs.append(memplex.frogs[index])\n",
        "                keys.append(key)\n",
        "                k+=1\n",
        "\n",
        "     def best(self):\n",
        "         local_best =  max(self.frogs, key=lambda frog: frog.value)\n",
        "         return local_best\n",
        "\n",
        "     def worst(self):\n",
        "         local_worst =  min(self.frogs, key=lambda frog: frog.value)\n",
        "         return local_worst\n"
      ],
      "metadata": {
        "id": "TjSRqkS6gsQL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Population:\n",
        "     def __init__(self,n_clusters, n_population ,n_docs, docs_vector):\n",
        "        answers = np.random.randint(0, n_clusters, size=(n_population , n_docs))\n",
        "        self.frogs = []\n",
        "        i=0\n",
        "        for answer in answers:\n",
        "           frog = Frog(tuple(answer),docs_vector,n_clusters)\n",
        "           self.frogs.append(frog)\n",
        "           print(i,frog.value)\n",
        "           i+=1\n",
        "\n",
        "     def clear_frogs(self):\n",
        "        self.frogs.clear()\n",
        "\n",
        "     # Best frog in population\n",
        "     def global_best(self,memplexes):\n",
        "        local_bests = []\n",
        "        for memplex in memplexes:\n",
        "            local_best =  max(memplex.frogs, key=lambda frog: frog.value)\n",
        "            local_bests.append(local_best)\n",
        "        global_best =  max(local_bests, key=lambda frog: frog.value)\n",
        "        return global_best\n",
        "\n",
        "     def shufeling(self,memplexes):\n",
        "         output = []\n",
        "         for memplex in memplexes:\n",
        "            output = output+ memplex.frogs\n",
        "         self.frogs = output"
      ],
      "metadata": {
        "id": "fMar5YE7ryrZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SFLA:\n",
        "     def  __init__(self,n_clusters, max_iteration, docs):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iteration =  max_iteration\n",
        "        self.docs = docs\n",
        "        self.n_population = 400 # Frogs number\n",
        "        self.memplex_size = 20 #define as m\n",
        "        self.n_memplex = 20 #define as n\n",
        "        self.local_iteration = 10 #Iteration As local search\n",
        "        self.n_submemplex = 5\n",
        "        self.docs_vector = docs_as_tfidf(docs)  #Convert documents as tfidf values\n",
        "        self.n_docs = len(docs)\n",
        "\n",
        "\n",
        "     def create_memplexes(self,population,n_memplex):#ّFrogs are distributed fairly in the memplexes\n",
        "             population = sorted(population.frogs, key=lambda frog: frog.value)\n",
        "             memplexes = []\n",
        "             for i in range(n_memplex):\n",
        "                 memplex = Memplex()\n",
        "                 memplexes.append(memplex)\n",
        "             for i in range(self.n_population):\n",
        "                 memplexes[i % n_memplex].frogs.append(population[i])\n",
        "             return memplexes\n",
        "\n",
        "\n",
        "\n",
        "     def search(self):\n",
        "        population = Population(self.n_clusters, self.n_population, self.n_docs, self.docs_vector)\n",
        "        for i in range(self.max_iteration):\n",
        "           memplexes = self.create_memplexes(population,self.n_memplex)\n",
        "           population.clear_frogs()\n",
        "           for j in range(self.n_memplex):\n",
        "               submemplex = Submemplex(memplexes[j],self.n_submemplex,self.memplex_size)\n",
        "               memplexes[j].frogs_to_remove(submemplex)\n",
        "               print(i,j,len(memplexes[j].frogs))\n",
        "               for k in range(self.local_iteration):\n",
        "                    lfrog_best = submemplex.best()\n",
        "                    lfrog_worst = submemplex.worst()\n",
        "                    frog_out = lfrog_worst.cross_over(lfrog_best, self.docs_vector, self.n_clusters)\n",
        "                    if (lfrog_worst.value < frog_out.value ):\n",
        "                         submemplex.frogs.remove(lfrog_worst)\n",
        "                         submemplex.frogs.append(frog_out)\n",
        "                    else:\n",
        "                         gfrog_best = population.global_best(memplexes)\n",
        "                         frog_out = gfrog_best.cross_over(lfrog_worst, self.docs_vector, self.n_clusters)\n",
        "                         if (lfrog_worst.value<frog_out.value):\n",
        "                              submemplex.frogs.remove(lfrog_worst)\n",
        "                              submemplex.frogs.append(frog_out)\n",
        "                         else:\n",
        "                              frog_out = gfrog_best.mutation(self.docs_vector,self.n_clusters)\n",
        "                              submemplex.frogs.remove(lfrog_worst)\n",
        "                              submemplex.frogs.append(frog_out)\n",
        "               memplexes[j].add_frogs(submemplex)\n",
        "           gfrog_best = population.global_best(memplexes)\n",
        "           print(gfrog_best.answer)\n",
        "           print(gfrog_best.value)\n",
        "           population.shufeling(memplexes)"
      ],
      "metadata": {
        "id": "Hvh9lxf7ddZ6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = dataset.data[0:200]\n",
        "sfla = SFLA(4,50,docs)\n",
        "sfla.search()"
      ],
      "metadata": {
        "id": "ull9d7AGWeSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT5WJIYfAWKq",
        "outputId": "18c1c8b6-d40b-4077-f839-cabdc954854c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1382\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19326683304032288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18415250785552104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2007137789503999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.38653366608064577, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16495515310449496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1601442908505651, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2152822099231195, 0.0, 0.0, 0.0, 0.0, 0.19326683304032288, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16850914326011535, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14618549985564544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14727476761437713, 0.0, 0.0, 0.22157851297615083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15722554087429888, 0.0, 0.0, 0.2007137789503999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22157851297615083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13580127590355345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20501724188127193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14618549985564544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13108313813948552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.20982810413520178, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "population_size = 400 # Frogs number\n",
        "memplex_num = 20 #define as m\n",
        "memplex_size = 20 #define as n\n",
        "max_iteration = 100 #Total Iteration\n",
        "local_iteration = 10 #Iteration As local search\n",
        "n_clusters = 4\n",
        "docs = dataset.data[0:500]\n",
        "docs_vector = docs_as_tfidf(docs)\n",
        "print(list(docs_vector[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal Functional format"
      ],
      "metadata": {
        "id": "pHjgs54g8DVk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU_Vs63UAfxR"
      },
      "outputs": [],
      "source": [
        "#Calculate sum of squared error(SSE) as similarity of each documents with the cluster mean in document\n",
        "def SSE(cluster,doc_mean):\n",
        "  size = len(cluster)\n",
        "  sse=0\n",
        "  for doc in cluster:\n",
        "    sse += cosin_sim(doc,doc_mean)**2\n",
        "  sse = sse/size\n",
        "  return sse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djW8MEZJAhbt"
      },
      "outputs": [],
      "source": [
        "#Calculate similarity between clusters\n",
        "def BC(doc_means):\n",
        "   BC=0\n",
        "   size = len(doc_means)\n",
        "   for i in range(size):\n",
        "      for j in range(i+1,size):\n",
        "          BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "   return BC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8QcCXYyAlbp"
      },
      "outputs": [],
      "source": [
        "#Calculate similarity within clusters\n",
        "def WC(clusters):\n",
        "    WC = 0\n",
        "    for cluster in clusters:\n",
        "        doc_mean = np.average(cluster, axis=0)\n",
        "        WC += SSE(cluster,doc_mean)\n",
        "    return WC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctgFGZq4AoMy"
      },
      "outputs": [],
      "source": [
        "def build_clusters(answer,docs_vector,n_clusters):\n",
        "   clusters = []\n",
        "   for i in range(n_clusters):\n",
        "       clusters.append([])\n",
        "   for j in range(len(answer)):\n",
        "       if -1 < answer[j]:\n",
        "        clusters[answer[j]].append(docs_vector[j])\n",
        "   return clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxmKqWWwAr-p"
      },
      "outputs": [],
      "source": [
        "def fitness(answer,docs_vector,size):\n",
        "   doc_means = []\n",
        "   clusters = build_clusters(answer,docs_vector,size)\n",
        "   for i in range(size):\n",
        "       doc_means.append(\n",
        "          np.average(clusters[i], axis=0)\n",
        "       )\n",
        "   wc = WC(clusters) #Calculate similarity within clusters\n",
        "   print(wc)\n",
        "   bc = BC(doc_means) #Calculate similarity between clusters\n",
        "   print(bc)\n",
        "   fitness = wc/bc\n",
        "   return fitness"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jY-Qp-BGzBWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9KMmJLRAyA9"
      },
      "outputs": [],
      "source": [
        "#perform 2 points cross over\n",
        "def cross_over(answer_a,answer_b):\n",
        "    frog_size = len(answer_a)\n",
        "    points = sorted(np.random.choice(np.arange(0,frog_size), size=2, replace=False))\n",
        "    child1 = answer_a[:points[0]] + answer_b[points[0]:points[1]] + answer_a[points[1]:]\n",
        "    child2 = answer_b[:points[0]] + answer_a[points[0]:points[1]] + answer_b[points[1]:]\n",
        "    fitness1 =  fitness(child1 ,docs_vector,n_clusters)\n",
        "    fitness2 = fitness(child2 ,docs_vector,n_clusters)\n",
        "    if fitness1 > fitness2: # return best child\n",
        "       return (child1 , fitness1)\n",
        "    else :\n",
        "       return (child2 , fitness2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7IQ2BZ6A2mE"
      },
      "outputs": [],
      "source": [
        "def best_and_worst(answers):\n",
        "     best =  max(answers, key=lambda x:x[1])\n",
        "     worst = min(answers, key=lambda x:x[1])\n",
        "     return best , worst"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl1HNpfnA4aH"
      },
      "outputs": [],
      "source": [
        "# Best frog in population\n",
        "def global_best(memplexes):\n",
        "     local_bests = []\n",
        "     for memplex in memplexes:\n",
        "         local_best =   max(memplex, key=lambda x:x[1])\n",
        "         local_bests.append(local_best)\n",
        "     global_best = max(local_bests, key=lambda x:x[1])\n",
        "     return global_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyxvE3VTA8CF"
      },
      "outputs": [],
      "source": [
        "def frogs_to_remove(sub_memplex , memplex):\n",
        "    for item in sub_memplex:\n",
        "       memplex.remove(item)\n",
        "    return memplex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_So4_XjBCHg"
      },
      "outputs": [],
      "source": [
        "def mutation(global_best,clusters_size):\n",
        "    new_ans = list(global_best)\n",
        "    size = int(len(global_best)/4)\n",
        "    indexes = np.random.choice(np.arange(0,len(global_best)), size=size, replace=False)\n",
        "    values= [random.randint(0, 3) for _ in range(size)]\n",
        "    for i in range(size):\n",
        "      new_ans[indexes[i]] = values[i]\n",
        "    return tuple(new_ans)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNAgxJGYBEX9"
      },
      "outputs": [],
      "source": [
        "def Create_memplexes(population,memplex_num):\n",
        "     population = list(reversed(sorted(population, key=lambda x: x[1])))\n",
        "     memplexes = []\n",
        "     population_size = len(population)\n",
        "     for i in range(memplex_num):\n",
        "         memplexes.append([])\n",
        "     for i in range(population_size):\n",
        "         memplexes[i % memplex_num].append(population[i])\n",
        "     return memplexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC9UfM-YnV8S"
      },
      "outputs": [],
      "source": [
        "def create_submemplex(memplex,memplex_size, submemplex_size):\n",
        "    sub_memplex = []\n",
        "    prob_list = []\n",
        "    keys = []\n",
        "    for i in range(memplex_size):\n",
        "       for j in range(2*(memplex_size-i)):\n",
        "          prob_list.append(i)\n",
        "    k=0\n",
        "    while(k!=submemplex_size):\n",
        "       index = random.choice(prob_list)\n",
        "       key = memplex[index][0]\n",
        "       if key not in keys:\n",
        "           sub_memplex.append(memplex[index])\n",
        "           keys.append(key)\n",
        "           k+=1\n",
        "    return sub_memplex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WghpigCiBH25"
      },
      "outputs": [],
      "source": [
        "#sh\n",
        "def shufeling(memplexes):\n",
        "    output = []\n",
        "    for memplex in memplexes:\n",
        "        output = output+ memplex\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEofbesdBRJZ"
      },
      "outputs": [],
      "source": [
        "def frog_leaping_search(docs_vector):\n",
        "                     answers=np.random.randint(0, n_clusters, size=(population_size , len(docs)))\n",
        "                     population = []\n",
        "                     i=0\n",
        "                     for answer in answers:\n",
        "                        i+=1\n",
        "                        frog = (tuple(answer),fitness(answer,docs_vector,n_clusters))\n",
        "                        pdb.set_trace()\n",
        "                        population.append(frog)\n",
        "                        print(i,frog[1])\n",
        "                     for i in range(max_iteration):\n",
        "                        memplexes = Create_memplexes(population, memplex_num)\n",
        "                        population.clear()\n",
        "                        for j in range(memplex_num):\n",
        "                            print(i,j,len(memplexes[j]))\n",
        "                            sub_memplex = create_submemplex(memplexes[j],memplex_size, 5)\n",
        "                            memplexes[j] =  frogs_to_remove(sub_memplex,memplexes[j])\n",
        "                            for k in range(local_iteration):\n",
        "                                ans_best, ans_worst = best_and_worst(sub_memplex)\n",
        "                                ans_out = cross_over(ans_best[0],ans_worst[0])\n",
        "                                if (ans_worst[1]<ans_out[1]):\n",
        "                                    sub_memplex.remove(ans_worst)\n",
        "                                    sub_memplex.append(ans_out)\n",
        "                                else:\n",
        "                                    g_best = global_best(memplexes)\n",
        "                                    ans_out = cross_over(g_best[0],ans_worst[0])\n",
        "                                    if (ans_worst[1]<ans_out[1]):\n",
        "                                       sub_memplex.remove(ans_worst)\n",
        "                                       sub_memplex.append(ans_out)\n",
        "                                    else:\n",
        "                                        ans_out = mutation(g_best[0],n_clusters)\n",
        "                                        fitness_out = fitness(ans_out,docs_vector,n_clusters)\n",
        "                                        sub_memplex.remove(ans_worst)\n",
        "                                        sub_memplex.append((ans_out , fitness_out))\n",
        "                            memplexes[j]= memplexes[j]+sub_memplex\n",
        "                            print(i,j,len(memplexes[j]))\n",
        "                        g_best = global_best(memplexes)\n",
        "                        print(g_best[0])\n",
        "                        print(g_best[1])\n",
        "                        population = shufeling(memplexes)\n",
        "                        print(len(population))\n",
        "                     return g_best, g_value, population"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykAWu-IWkba0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0FrmD4etKFsn"
      },
      "outputs": [],
      "source": [
        "\n",
        "g_best, g_value,population = frog_leaping_search(docs_vector)\n",
        "true = 0\n",
        "size = len(dataset.data)\n",
        "print(labels)\n",
        "print(list(g_best))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpjaxVNAtfGlDgdSkHrZm8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}