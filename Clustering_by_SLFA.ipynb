{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMjneguUVKmFWhhFbDG0XS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MHoseinHoushmand/Clustering_by_SLFA/blob/main/Clustering_by_SLFA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e2J1TujL22H1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c21290d5-a737-4c00-eaf6-cd7000b020d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3758 documents - 4 categories\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import pdb\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "categories = [\n",
        "    \"alt.atheism\",\n",
        "    \"comp.graphics\",\n",
        "    \"sci.space\",\n",
        "    \"rec.sport.hockey\",\n",
        "]\n",
        "\n",
        "dataset = fetch_20newsgroups(\n",
        "    remove=(\"headers\", \"footers\", \"quotes\"),\n",
        "    subset=\"all\",\n",
        "    categories=categories,\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        ")\n",
        "answers_list = []\n",
        "labels = dataset.target\n",
        "unique_labels, category_sizes = np.unique(labels, return_counts=True)\n",
        "true_k = unique_labels.shape[0]\n",
        "print(f\"{len(dataset.data)} documents - {true_k} categories\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def docs_as_tfidf(docs):\n",
        "  vectorizer = TfidfVectorizer(\n",
        "     max_df=0.5,\n",
        "     min_df=5,\n",
        "     stop_words=\"english\",\n",
        "  )\n",
        "\n",
        "  docs_vector = vectorizer.fit_transform(docs)\n",
        "  return docs_vector.toarray()"
      ],
      "metadata": {
        "id": "ERPNfqNYATbl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "population_size = 120 # Frogs number\n",
        "memplex_num = 12 #define as m\n",
        "memplex_size = 10 #define as n\n",
        "max_iteration = 150\n",
        "memplex_iteration = 8\n",
        "docs = dataset.data\n",
        "docs_vector = docs_as_tfidf(docs)"
      ],
      "metadata": {
        "id": "mT5WJIYfAWKq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def cosin_sim(a,b):\n",
        "   return cosine_similarity([a], [b])[0][0]\n",
        ""
      ],
      "metadata": {
        "id": "5Y_4pWLVAZIh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "def SSE(cluster,doc_mean):\n",
        "  size = len(cluster)\n",
        "  sse=0\n",
        "  for doc in cluster:\n",
        "    sse += cosin_sim(doc,doc_mean)**2\n",
        "  sse = sse/size\n",
        "  return sse"
      ],
      "metadata": {
        "id": "wU_Vs63UAfxR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.linalg import norm\n",
        "def BC(doc_means):\n",
        "   BC=0\n",
        "   size = len(doc_means)\n",
        "   for i in range(size):\n",
        "      for j in range(i+1,size):\n",
        "          BC += cosin_sim(doc_means[i],doc_means[j])**2\n",
        "   return BC"
      ],
      "metadata": {
        "id": "djW8MEZJAhbt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def WC(clusters):\n",
        "    WC = 0\n",
        "    for cluster in clusters:\n",
        "        doc_mean = np.average(cluster, axis=0)\n",
        "        WC += SSE(cluster,doc_mean)\n",
        "    return WC"
      ],
      "metadata": {
        "id": "k8QcCXYyAlbp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_clusters(answer,docs_vector,clusters_size):\n",
        "   clusters = []\n",
        "   for i in range(clusters_size):\n",
        "       clusters.append([])\n",
        "   for j in range(len(answer)):\n",
        "       if -1 < answer[j]:\n",
        "        clusters[answer[j]].append(docs_vector[j])\n",
        "   return clusters"
      ],
      "metadata": {
        "id": "ctgFGZq4AoMy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fitness(answer,docs_vector,clusters_size):\n",
        "   doc_means = []\n",
        " #  pdb.runcall(build_clusters,answer,docs_vector,clusters_size)\n",
        "   clusters = build_clusters(answer,docs_vector,clusters_size)\n",
        "   for i in range(clusters_size):\n",
        "       doc_means.append(\n",
        "          np.average(clusters[i], axis=0)\n",
        "       )\n",
        "   wc = WC(clusters)\n",
        "   bc = BC(doc_means)\n",
        "   fitness = wc/bc\n",
        "   return fitness"
      ],
      "metadata": {
        "id": "UxmKqWWwAr-p"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def cross_over(answer_a,answer_b):\n",
        "    size = len(answer_a)\n",
        "    output = []\n",
        "    for i in range(size):\n",
        "       choice = random.choice([0,1])\n",
        "       if choice == 0:\n",
        "          output.append(answer_a[i])\n",
        "       else:\n",
        "          output.append(answer_b[i])\n",
        "    return tuple(output)"
      ],
      "metadata": {
        "id": "G9KMmJLRAyA9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_and_worst(answers):\n",
        "     best =  max(answers, key=answers.get)\n",
        "     worst = min(answers, key=answers.get)\n",
        "     return tuple(best) , tuple(worst)\n",
        ""
      ],
      "metadata": {
        "id": "I7IQ2BZ6A2mE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def global_best(memplexes):\n",
        "     local_bests = {}\n",
        "     for memplex in memplexes:\n",
        "         local_best =  max(memplex, key=memplex.get)\n",
        "         local_bests[local_best]= memplex[local_best]\n",
        "     global_best = max(local_bests, key=local_bests.get)\n",
        "     return global_best, local_bests[global_best]\n",
        ""
      ],
      "metadata": {
        "id": "sl1HNpfnA4aH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keys_to_remove(keys , dict):\n",
        "   for k in keys:\n",
        "      if k in dict:\n",
        "          dict.pop(k)\n",
        "   return dict"
      ],
      "metadata": {
        "id": "IyxvE3VTA8CF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mutation(global_best,clusters_size):\n",
        "    new_ans = list(global_best)\n",
        "    size = int(len(global_best)/4)\n",
        "    indexes = np.random.choice(np.arange(0,len(global_best)), size=size, replace=False)\n",
        "    values= [random.randint(0, 3) for _ in range(size)]\n",
        "    for i in range(size):\n",
        "      new_ans[indexes[i]] = values[i]\n",
        "    return tuple(new_ans)"
      ],
      "metadata": {
        "id": "q_So4_XjBCHg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Create_memplexes(population,memplex_num):\n",
        "     memplexes = []\n",
        "     keys = list(population.keys())\n",
        "     population_size = len(population)\n",
        "     for i in range(memplex_num):\n",
        "         memplexes.append({})\n",
        "     for i in range(population_size):\n",
        "         memplexes[i % memplex_num][keys[i]] = population[keys[i]]\n",
        "     return memplexes"
      ],
      "metadata": {
        "id": "fNAgxJGYBEX9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shufeling(memplexes):\n",
        "    output = {}\n",
        "    for memplex in memplexes:\n",
        "        output.update(memplex)\n",
        "    return output"
      ],
      "metadata": {
        "id": "WghpigCiBH25"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "def frog_leaping_search(docs_vector,cluster_size):\n",
        "             answers=np.random.randint(0, cluster_size, size=(population_size , len(dataset.data)))\n",
        "             print(list(answers[0]))\n",
        "             population = {}\n",
        "             i=0\n",
        "             for answer in answers:\n",
        "               # pdb.runcall(fitness,answer,docs_vector,cluster_size)\n",
        "                i+=1\n",
        "                population[tuple(answer)] = fitness(answer,docs_vector,cluster_size)\n",
        "                print(i,population[tuple(answer)])\n",
        "\n",
        "             for i in range(max_iteration):\n",
        "                population = dict( sorted(population.items(), key=operator.itemgetter(1), reverse=True))\n",
        "           #    pdb.runcall(Create_memplexes,population, memplex_num)\n",
        "                memplexes = Create_memplexes(population, memplex_num)\n",
        "                population.clear()\n",
        "              #  pdb.set_trace()\n",
        "                for j in range(memplex_num):\n",
        "                    print(i,j,len(memplexes[j]))\n",
        "                    sub_memplex = dict(random.sample(list(memplexes[j].items()),k=5))\n",
        "                    memplexes[j] =  keys_to_remove(sub_memplex.keys(),memplexes[j])\n",
        "                    for k in range(memplex_iteration):\n",
        "                        #pdb.runcall(best_and_worst,sub_memplex)\n",
        "\n",
        "                   #     for m in sub_memplex:\\n\",\n",
        "                    #        print(list(m))\n",
        "                        ans_best, ans_worst = best_and_worst(sub_memplex)\n",
        "                        ans_out = cross_over(ans_best,ans_worst)\n",
        "                        fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "                        #sec B,\n",
        "                        ###############################################\n",
        "                        if len(sub_memplex)< 5:\n",
        "                               print(\"errrrrrrrrrrrorrrrrrrrrrrrrB\")\n",
        "                               pdb.set_trace()\n",
        "                      ###############################################\n",
        "                      #pdb.runcall(best_and_worst,sub_memplex)\n",
        "                       # print(\"############\")\n",
        "\n",
        "\n",
        "                        if (sub_memplex[ans_worst]<fitness_out):\n",
        "                            del sub_memplex[ans_worst]\n",
        "                            sub_memplex[ans_out] = fitness_out\n",
        "                            #sec C\n",
        "                           ###############################################\n",
        "                            if len(sub_memplex)< 5:\n",
        "                                      print(\"errrrrrrrrrrrorrrrrrrrrrrrrC\")\n",
        "                                      pdb.set_trace()\n",
        "                          ###############################################\n",
        "                        else:\n",
        "                           # pdb.runcall(global_best,memplexes)\n",
        "                            g_best, g_value = global_best(memplexes)\n",
        "                            ans_out = cross_over(g_best,ans_worst)\n",
        "                            #sec D\n",
        "                            ###############################################\n",
        "                            if len(sub_memplex)< 5:\n",
        "                                  print(\"errrrrrrrrrrrorrrrrrrrrrrrrD\")\n",
        "                                  pdb.set_trace()\n",
        "                            ###############################################\n",
        "                            fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "                            if (sub_memplex[ans_worst] < fitness_out):\n",
        "                                del sub_memplex[ans_worst]\n",
        "                                sub_memplex[ans_out] = fitness_out\n",
        "                                #sec E\n",
        "                                ###############################################\n",
        "                                if len(sub_memplex)< 5:\n",
        "                                      print(\"errrrrrrrrrrrorrrrrrrrrrrrrE\")\n",
        "                                      pdb.set_trace()\n",
        "                            ###############################################\n",
        "                            else:\n",
        "                           #     print(\\\"#########\\\")\n",
        "                            #    for m in sub_memplex:\n",
        "                             #        print(list(m))\n",
        "                                del sub_memplex[ans_worst]\n",
        "                             #   pdb.runcall(mutation,g_best,cluster_size)\n",
        "                                ans_out = mutation(g_best,cluster_size)\n",
        "                                fitness_out = fitness(ans_out,docs_vector,cluster_size)\n",
        "                                sub_memplex[ans_out] = fitness_out\n",
        "                                #sec F\n",
        "                                ###############################################\n",
        "                                if len(sub_memplex)< 5:\n",
        "                                      print(\"errrrrrrrrrrrorrrrrrrrrrrrrF\")\n",
        "                                      pdb.set_trace()\n",
        "                               ###############################################\n",
        "                #     pdb.runcall(join_dicts,memplexes[j],sub_memplex)\n",
        "                    memplexes[j].update(sub_memplex)\n",
        "                g_best, g_value = global_best(memplexes)\n",
        "               # pdb.runcall(show_result,g_best)\n",
        "                answers_list.append(g_best)\n",
        "                print(g_best)\n",
        "                print(g_value)\n",
        "                population = shufeling(memplexes)\n",
        "             return g_best, g_value, population"
      ],
      "metadata": {
        "id": "VEofbesdBRJZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g_best, g_value,population = frog_leaping_search(docs_vector,4)\n",
        "true = 0\n",
        "size = len(dataset.data)\n",
        "print(labels)\n",
        "print(list(g_best))"
      ],
      "metadata": {
        "id": "0FrmD4etKFsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}